---
title: "S1b Data Code"
author: "Ian Hajnosz"
date: "3/17/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First, loading in helpful the packages
```{r eval=FALSE}
library(dplyr)
library(tidyverse)
library(readr)
library(ggplot2)
library(viridis)
library(gridExtra)
library(bmlm)
library(brms)
library(qgraph)
library(bayestestR)
library(ggExtra)
options(mc.cores = parallel::detectCores())
```
## Data Entry & Cleaning

### Data Loading
Now to load in the data. I'm saving an "anchor" dataframe (df) as a reference point to the original data. We'll iterate using the df dataframe from now on.
```{r}
df <- df_anchor <- read_csv("Ian+Study+1b_March+17,+2022_09.18.csv")
```

### Data Cleaning

#### Removing Unnecessary Data
Removing Unnecessary columns. This includes removing  participated metadata Qualtrics automatically collects in their surveys, as well as most of the "DO" variables--these are the scale and item ordering within each survey block. Items were randomized within their respective scale, and scales were randomly presented within their given survey block in the survey flow. We can see that randomization did work, but otherwise these aren't helpful for us now.
Note: We do keep one "DO" variable called, FL_5_DO--this column names us the video the participant viewed in the survey. We'll use this variable to double check participant attentiveness later on
```{r}
df <- select(df,
       -(StartDate:Progress)) #removing participant metadata columns (unnecessary variables)

df <- select(df,
       -(Finished:UserLanguage)) #removing participant metadata columns (unnecessary variables)

df <- df[-c(1,2),] #removing participant metadata rows (first two rows are metadata)

df <- select(df,
       -c(Aut1_DO, Rel1_DO, Comp1_DO, EC_DO, Attach_DO,KM_P_DO, KM_CSR_DO, KM_M_DO, KM_L_DO,PANAS_DO, Aut2_DO, Rel2_DO, Comp2_DO, Vid_SelfRep_DO, FL_3_DO, FL_31_DO, FL_33_DO, SC0)) # removing unnecessary display ordering columns
```

#### Reference ID Variable
Now we can creating a separate ID variable, just for reference sake
```{r}
df$id <- 1:nrow(df)
df <- df %>% 
  select(id, everything()) #moving the id variable to the front of the df
```

#### Renaming Columns
We have some columns with unhelpful names. Let's change that. We'll also change that FL_5_DO from earlier into a more recognizable and helpful variable name.

```{r}
df <- rename(df,
       Neutral_Timer = 'Timer_Neutral_Page Submit',
       KM_Timer = 'Timer_KM_Page Submit',
       Amuse_Timer = 'Timer_Amuse_Page Submit',
       Cond = FL_5_DO,
       Vid_Issue_Text = Vid_Issue_2_TEXT,
       Race_Text = Race_10_TEXT,
       SexualOr_Text = SexualOr_6_TEXT,
       Age = Age_1,
       Survey_Duration = `Duration (in seconds)`)
```

#### Recoding Responses
Let's try to simplify some of the character responses in our new Cond variable into numerics for easier organization.
We can also recode answers to that attention check item. Participants were instructed to only select "Not at all" which is also coded as 0. Therefore, any participant who responded as 0 passed, any other response is an attention check fail.
```{r}
df <- mutate(df, 
             Cond = recode(Cond,
                'VideoCondition1"ThaiMedicine"Zickfeldetal.2019' = "KM",
                'VideoNeutral1"CleanHardwoodFloors"(Riveraetal.,2019)' = "Neutral",
                'VideoCondition2"MrBean"Zickfeldetal.,2019' = "Amuse"))

table(df$AttCheck_1, exclude = NULL)
df$AttCheck_1 <- ifelse(df$AttCheck_1 == 0,
                        "Pass",
                        "Fail")
table(df$AttCheck_1)#checking ifelse worked properly

```

#### Checing Variable Typing
Now let's make sure the variables are the correct type of data. I.e. that numeric data are being treated as numeric, characters are factors etc.

Numeric Data
```{r}
df$Survey_Duration <- as.numeric(df$Survey_Duration)
df[, c(4:71, 73:113)] <- sapply(df[, c(4:71, 73:113)], as.numeric) #just choosing all the columns by index to be made numeric
df$Age <- as.numeric(df$Age)
```

Factor Data
```{r}
#Consent
table(df$Consent)#only "1"s in here, so only a single level to label
df$Consent <- factor(df$Consent, labels = "Consent")

#Video Self Report
table(df$Vid_SelfRep) #based on the survey, 2 = Neutral Video description, 3 = KM Video description, 6 = Amusement Video Description. All other responses were fake video descriptions
df$Vid_SelfRep <- factor(df$Vid_SelfRep, labels = c(
  "Fake1",
  "Neutral",
  "KM",
  "Amuse",
  "Fake7"
))
table(df$Vid_SelfRep)#Video self report changes line up with original

#Video Audio
table(df$Vid_Audio) #based on the survey, 1 = No audio, 2 = Yes audio
df$Vid_Audio <- factor(df$Vid_Audio, labels = c(
  "No",
  "Yes"
))
table(df$Vid_Audio)

#Video Issues
table(df$Vid_Issue)#Based on survey, 1= No, 2 = Yes
df$Vid_Issue <- factor(df$Vid_Issue, labels = c(
  "No",
  "Yes"
))
table(df$Vid_Issue)

#Video Issues Character String
summary(df$Vid_Issue_Text)#can keep as a character string
table(df$Vid_Issue_Text) #just to see spread of issues
df %>% 
  filter(!is.na(Vid_Issue_Text))#Just to see the exact participants with video issues

#Previous Experience with Video
table(df$Vid_PrevExp)#Based on survey, 1 = No, 2 = Yes
df$Vid_PrevExp <- factor(df$Vid_PrevExp, labels = c(
  "No",
  "Yes"
))
table(df$Vid_PrevExp)

#Gender
table(df$Gender) #Based on survey, 0 = Female, 1 = Male, 2 = Trans Female, 3 = Trans Male(unrepresented in data), 4 = Nonbinary, 5 = Bigender, 6 = Agender

df$Gender <- factor(df$Gender, labels = c(
  "Female",
  "Male",
  "Trans Female",
  "Nonbinary",
  "Bigender",
  "Agender"
))
table(df$Gender)

#Gender, Write-In
table(df$Gender_7_TEXT)# No write-in gender responses

#Race
table(df$Race) #Based on survey, 0 = White, 1 = Black, African, Caribbean, 2 = Hispanic, Latino, Chicano, 3 = East Asian, 4 = South Asian, 5 = Southeast Asian, 6 = West Asian (unrepresented in data), 7 = Middle Eastern, Arab, 8 = Aboriginal, Indigenous, Native (unrepresented in data), 9 = Mixed or Multiple Ethnic Groups, 10 = Write-in
df$Race <- factor(df$Race, labels = c(
  "White, Caucasian, Anglo",
  "Black, African, Caribbean",
  "Other Write-In",
  "Hispanic, Latino, Chicano",
  "East Asian",
  "South Asian",
  "Southeast Asian",
  "Middle Eastern, Arab",
  "Mixed or Multiple Groups"
))
table(df$Race)

#Race, Write-In
table(df$Race_Text)
df$Race[df$Race_Text == "White and Hispanic"] <- "Mixed or Multiple Groups"
df$Race[df$Race_Text == "White, european"] <- "White, Caucasian, Anglo"

#Education
table(df$Education) # Based on survey, 0 = "GCSE, O-Levels, or Standard Grades", 1 = "A-Levels or Highers/Advanced Highers", 2 = "Vocational degree (e.g., SVQ, HNC, HND)", 3 = "Undergraduate degree (e.g., BSc, BA)", 4 = "Master's degree (e.g., MSc, MPhil)", 5 = "PhD, PsyD", 6 = "Other advanced or professional degree (e.g., MD, JD)"
df$Education <- factor(df$Education, labels = c(
  "GCSE, O-Levels, or Standard Grades",
  "A-Levels or Highers/Advanced Highers",
  "Vocational degree (e.g., SVQ, HNC, HND)",
  "Undergraduate degree (e.g., BSc, BA)",
  "Master's degree (e.g., MSc, MPhil)",
  "PhD, PsyD", 
  "Other advanced or professional degree (e.g., MD, JD)"
))
table(df$Education)

#Student
table(df$Student) # Based on survey, 0 = No, 1 = Yes
df$Student <- factor(df$Student, labels = c(
  "No",
  "Yes"
))
table(df$Student)

#Employed
table(df$Employed) # Based on survey, 0 = No, 1 = Part-time, 2 = Full-time
df$Employed <- factor(df$Employed, labels = c(
  "No",
  "Part-time",
  "Full-time"
))
table(df$Employed)

#Income
table(df$Income) # Based on survey, 0 = £0-£12,500, 1 = £12,501-£14,549, 2 = £14,550-£24,944, 3 = £24,945-£43,430, 4 = £43,431-£150,000, 5 = £150,001+
df$Income <- factor(df$Income, labels = c(
  "£0-£12,500",
  "12,501-£14,549",
  "£14,550-£24,944",
  "£24,945-£43,430",
  "£43,431-£150,000",
  "£150,001+"
))
table(df$Income)

#Sexual Orientation
table(df$SexualOr) # Based on survey, 0 = Heterosexual, Straight, 1 = Gay, 2 = Lesbian, 3 = Queer, 4 = Bisexual, Pansexual, 5 = Demisexual, 6 = Asexual, 7 = Other Write-In (not represented in these data)
df$SexualOr <- factor(df$SexualOr, labels = c(
  "Heterosexual, Straight",
  "Gay",
  "Lesbian",
  "Queer",
  "Bisexual, Pansexual",
  "Demisexual",
  "Asexual",
  "Other Write-In"
))
table(df$SexualOr)

#Sexual Orientation, Write-Ins
table(df$SexualOr_Text) #no corrections applicable

#Condition, Re-leveling for dummy coding
table(df$Cond)
df$Cond <- factor(df$Cond)
contrasts(df$Cond) # "Amuse", alphabetically first, is the current reference grouup
df$Cond <- fct_relevel(df$Cond, "Neutral") #re-leveling for reference group
```
Now to do some broad checks across the variables to see if any outliers, impossible ratings appear etc.
```{r}
summary(df)
```
### Pre-Processing
Now that the variables are entered correctly, we can go about making the appropriate transformations, reverse-codings etc. on those variables

#### Reverse-Codings and collating scores
For reverse coding, we can use the equation: Reversed score = (total available responses in scale + 1) - Reported Score
This way, in a 7-item, 1-7 coding scheme, 1s become 7s ((7+1)-1 = 7), 2s become 6s ((7+1)-2 = 6) etc.

T1 Autonomy Satisfaction & Frustration
```{r}
#Aut Sat items: 1, 2, 3, 4
df$ANS_1 <- rowMeans(df[,c("Aut1S_1", "Aut1S_2", "Aut1S_3", "Aut1S_4")], na.rm = T)

#Aut Frus items: 5, 6, 7, 8
df$ANF_1 <- rowMeans(df[,c("Aut1F_5", "Aut1F_6", "Aut1F_7", "Aut1F_8")], na.rm = T)
```

T1 Relatedness Satisfaction & Frustration
```{r}
#Rel Sat items: 1, 2, 3, 4
df$RNS_1 <- rowMeans(df[,c("Rel1S_1", "Rel1S_2", "Rel1S_3", "Rel1S_4")], na.rm = T)

#Rel Frus itmes: 5, 6, 7, 8
df$RNF_1 <- rowMeans(df[,c("Rel1F_5", "Rel1F_6", "Rel1F_7", "Rel1F_8")], na.rm = T)
```

T1 Competency Satisfaction & Frustration
```{r}
#Comp Sat items: 1, 2, 3, 4
df$CNS_1 <- rowMeans(df[,c("Comp1S_1", "Comp1S_2", "Comp1S_3", "Comp1S_4")], na.rm = T)

#Comp Frus itmes: 5, 6, 7, 8
df$CNF_1 <- rowMeans(df[,c("Comp1F_5", "Comp1F_6", "Comp1F_7", "Comp1F_8")], na.rm = T)
```
Empathic Concern
Note, that this has a zero-point in it's scale. This means the reverse score equation is 
Reversed score = (total available responses in scale - 1) - Reported Score.
This way, in a 5-item, 0-4 coding scheme, 0s become (5-1)-0 = 4), 1s become (5-1)-1 = 3 etc.
```{r}
summary(df$EC_1)#Correctly on the 0-4 scale

#EC items with reversed coding (r): 1, 2R, 3, 4R, 5R, 6, 7
df$EC_2R <- 4 - df$EC_2
df$EC_4R <- 4 - df$EC_4
df$EC_5R <- 4 - df$EC_5
df$EC <- rowMeans(df[, c("EC_1", "EC_2R", "EC_3", "EC_4R", "EC_5R", "EC_6", "EC_7")], na.rm = T)

```

General/Global Attachment: Avoidance and Anxiety
Note, for reverse coding without a zero point, we can use the equation:
Reversed score = (total available responses in scale + 1) - Reported Score
This way, in a 7-item, 1-7 coding scheme, 1s become 7s ((7+1)-1 = 7), 2s become 6s ((7+1)-2 = 6) etc.
```{r}
#Attachment Items: 1 - 9
summary(df$Attach_1) #properly on 1-7 scale

##Attachment Avoidance
#Attachment items with reversed coding (r): 1R, 2R, 3R, 4R, 5, 6
df$Attach_1R <- 8 - df$Attach_1
df$Attach_2R <- 8 - df$Attach_2
df$Attach_3R <- 8 - df$Attach_3
df$Attach_4R <- 8 - df$Attach_4
df$Attach_avd <- rowMeans(df[, c("Attach_1R", "Attach_2R", "Attach_3R", "Attach_4R", "Attach_5", "Attach_6")], na.rm = T)

##Attachment Anxiety
#Attachment items (no reverse coding): 7,8,9
df$Attach_anx <- rowMeans(df[, c("Attach_7", "Attach_8", "Attach_9")], na.rm = T)
```
Kama Muta (KM)
KM is made up of 5 aspects, all measured separately: Physical reaction (KM_P), Communal sharing relationship appraisal (KM_CSR), prosocial Motivation (KM_M), positive affect, and lexical label (KM_L). We remove positive affect here for the sake of separately measuring it more robustly via the PANAS.

```{r}
#KM_P (Physiology) Items: KM_P_1-12
df$KM_P <- rowMeans(df[, c("KM_P_1","KM_P_2", "KM_P_3", "KM_P_4" ,"KM_P_5", "KM_P_6", "KM_P_7", "KM_P_8", "KM_P_9", "KM_P_10", "KM_P_11","KM_P_12")], na.rm = T)

#KM_CSR (Communal Sharing Relationship appraisal) Items: KM_CSR_1-4
df$KM_CSR <- rowMeans(df[, c("KM_CSR_1","KM_CSR_2","KM_CSR_3", "KM_CSR_4")], na.rm = T)

#KM_M (prosocial Motive): KM_M_1-4
df$KM_M <- rowMeans(df[, c("KM_M_1","KM_M_2", "KM_M_3", "KM_M_4")], na.rm = T)

#KM_L (Lexical Label): KM_L_1-3
df$KM_L <- rowMeans(df[, c("KM_L_1", "KM_L_2", "KM_L_3")], na.rm = T)
```

The KAMMUS Scale technically only reflects the likelihood of a given experience being kama muta, rather than a direct measure of the emotion itself. As such, a complete KM score cannot be summed together. We instead directly apply a probability function to the kama muta scores to quantitatively reflect this scale issue.

KM_Avg
First we compile a single KM average. Note the scale metric of the KAMMUS is 0-6. 3 is the midpoint, whereby scores above 3 are middling indicator of the experience being KM, while scores of 0 ("Not at All") and 6 ("A Lot") reflect very low and very high likelihood of the experience being KM. Therefore, an average score across all subscales will reflect similarly (e.g. the equivalent of marking 0 on every subscale item, will have an average of 0, marking very low likelihood. Marking a 6 on every subscale item will have an average of 7, marking very high likelihood.)

KM_Scl
We apply a sigmoid function to create reflect a non-linear scaling of these scores to reflect "probablity" (which is typically expressed via a sigmoid function a la logistical regressions). Note, the sigmoid function f(x) = 1/(1+e^-x) means that f(0) = 0.5 or 50% probablity. The goal is therefore to have 3, the middle of the KAMMUS scale, to reflect this 50% probability--such that scores above 3 mark higher likelihoods, lower scores mark lower likelihoods. I.e. we center scale the KAMMUS scores to 3

pKM
"Probability of KM", or p(KM), is the final implementation of the sigmoid function on this centered KM variable. **Note, this study's initial focus is on disentangling PA's influence, so remember that KM effects with this construction are sans PA**

```{r}
df$KM_Avg <- (df$KM_P + df$KM_CSR + df$KM_M + df$KM_L)/4

df$KM_Scl <- df$KM_Avg - 3

df$pKM <- 1/(1+(exp(1)^-(df$KM_Scl)))
```

You can see this non-linear pathway by comparing the KM average scores to this new pKM "probability" variable
```{r}
library(ggplot2)
ggplot(df, aes(x = KM_Scl, y = pKM)) +
  geom_point() #Average KM scores of 3 middle of the scale, now zeroed, are considered 50% likely to have experienced KM.
```


PANAS: Positive and Negative Affect
```{r}
##Negative Affect
#Negative items (no reverse coding): PANAS_NA1-5
df$NegAff <- rowMeans(df[,c("PANAS_NA1", "PANAS_NA2", "PANAS_NA3", "PANAS_NA4", "PANAS_NA5")], na.rm = T) 

##Positive Affect
#Positive items (no reverse coding): PANAS_PA1-5
df$PosAff <- rowMeans(df[,c("PANAS_PA1", "PANAS_PA2", "PANAS_PA3", "PANAS_PA4", "PANAS_PA5")], na.rm = T) 

```

T2 Autonomy Satisfaction & Frustration
```{r}
#Aut Sat items: 1, 2, 3, 4
df$ANS_2 <- rowMeans(df[,c("Aut2S_1", "Aut2S_2", "Aut2S_3", "Aut2S_4")], na.rm = T)

#Aut Frus items: 5, 6, 7, 8
df$ANF_2 <- rowMeans(df[,c("Aut2F_5", "Aut2F_6", "Aut2F_7", "Aut2F_8")], na.rm = T)
```

T2 Relatedness Satisfaction & Frustration
```{r}
#Rel Sat items: 1, 2, 3, 4
df$RNS_2 <- rowMeans(df[,c("Rel2S_1", "Rel2S_2", "Rel2S_3", "Rel2S_4")], na.rm = T)

#Rel Frus itmes: 5, 6, 7, 8
df$RNF_2 <- rowMeans(df[,c("Rel2F_5", "Rel2F_6", "Rel2F_7", "Rel2F_8")], na.rm = T)
```

T2 Competency Satisfaction & Frustration
```{r}
#Comp Sat items: 1, 2, 3, 4
df$CNS_2 <- rowMeans(df[,c("Comp2S_1", "Comp2S_2", "Comp2S_3", "Comp2S_4")], na.rm = T)

#Comp Frus itmes: 5, 6, 7, 8
df$CNF_2 <- rowMeans(df[,c("Comp2F_5", "Comp2F_6", "Comp2F_7", "Comp2F_8")], na.rm = T)
```


### Checking for Data Issues, Removing Problem Cases
The data processing is nearly done,now to check and attend to some final quality signs

To start, we had an Attention Check (AttCheck_1) earlier, but we also had a 2nd attention check--whether participants correctly self-reported the video they watched. Let's cross-reference that with the actual video they were shown. People who correctly reported their video pass, those who incorrectly report fail this 2nd attention check

```{r}
table(df$Vid_SelfRep, df$Cond)
```
Luckily it appears the incorrect answers (8 of them) are spread across all three conditions, suggesting the incorrect answers are not due to a condition's video being particularly difficult/vague to identify when asked directly. We can label these for the 2nd attention check

```{r}
df$AttCheck_2 <- ifelse(as.character(df$Vid_SelfRep) == as.character(df$Cond),
                        "Pass",
                        "Fail")
table(ifelse(as.character(df$Vid_SelfRep) == as.character(df$Cond),
                        "Pass",
                        "Fail")) #checking the new variable is tracking correctly to our previous table
```
### Evaluating Problems for Removal
How many people had issues with the audio?
```{r}
table(df$Vid_Audio)
```
Appears we have 9 people who didn't hear the audio.

Video Issues
```{r}
table(df$Vid_Issue)
unique(df$Vid_Issue_Text)
```
Had 7 people who had some video issue.

##### Timing
Participants who completed the entire survey in less than five minutes will not be kept (considering the videos alone are all roughly 2.5 minutes)
```{r}
summary(df$Survey_Duration)

subset(df, Survey_Duration <= 300) #300 seconds referring to 5minutes (60*5)
```


Time on Video Page
Each of the video page's had a timer. We can check now if people stayed on the page for the entire duration of the video.
Neutral duration: 201 seconds
KM duration: 176 seconds
Amuse duration: 146 seconds
```{r}
subset(df, Neutral_Timer < 201)
```
```{r}
subset(df, KM_Timer < 176)
```

```{r}
subset(df, Amuse_Timer < 146)
```
Some of these participants have timers very close to the actual video length, e.g. within 5 seconds. However, we cannot confirm whether participants immediately started the video upon entering, therefore even a timer showing 5 seconds less than the video length does not necessarily mean the participant watch all but 5 seconds of the video (i.e.the timer is more likely an overestimate, than underestimate, of the amount of the video they watched)

### Removal Criteria
Now to remove cases. We'll create a new "missing" variable to log the reasons for each cut

```{r}
df$missing <- NA
#Consent
df$missing[df$Consent != "Consent" | is.na(df$Consent)] <- "No Consent Confirmation"

#Duration
df$missing[df$Survey_Duration <=300] <- "Sub-5 Min Completion"

#Timers
df$missing[df$Neutral_Timer < 201] <- "Quick Neutral Video"
df$missing[df$KM_Timer < 176] <- "Quick KM Video"
df$missing[df$Amuse_Timer < 146] <- "Quick Amuse Video"

#Attention Checks
df$missing[df$AttCheck_2 == "Fail" | is.na(df$AttCheck_2)] <- "Failed 2nd Attention Check"
df$missing[df$AttCheck_1 == "Fail" | is.na(df$AttCheck_1)] <- "Failed 1st Attention Check"

#Technical Issues
df$missing[df$Vid_Audio == "No"] <- "No Video Audio"
df$missing[df$Vid_Issue == "Yes"] <- "Video Issue"
```

```{r}
missing_table <- table(df$missing)
missing_table
```
Now we can remove those people from the dataset
```{r}
df <- 
  df %>% filter(is.na(missing))
```

#### Standardizing Relevant Variables

Now to make some standardized versions of some variables we'll use in analysis later on 

```{r}
df$ANS_1_Z <- scale(df$ANS_1)
df$ANF_1_Z <- scale(df$ANF_1)
df$RNS_1_Z <- scale(df$RNS_1)
df$RNF_1_Z <- scale(df$RNF_1)
df$CNS_1_Z <- scale(df$CNS_1)
df$CNF_1_Z <- scale(df$CNF_1)
df$pKM_Z <- scale(df$pKM)
df$NegAff_Z <- scale(df$NegAff)
df$PosAff_Z <- scale(df$PosAff)
df$ANS_2_Z <- scale(df$ANS_2)
df$ANF_2_Z <- scale(df$ANF_2)
df$RNS_2_Z <- scale(df$RNS_2)
df$RNF_2_Z <- scale(df$RNF_2)
df$CNS_2_Z <- scale(df$CNS_2)
df$CNF_2_Z <- scale(df$CNF_2)
```

#### Final df Check
```{r}
summary(df)
```
Good, not seeing any unspoken for NAs

## Initial Visualizations
```{r eval=FALSE}
library(ggplot2)
library(viridis)
library(gridExtra)
```


```{r}
nrow(df) # = 352
#Age
p1 <- ggplot(df, aes(x = Age)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Age Distribution (n=352)",
       x = "Age (Binwidth = 1)",
       y = "Count")
#Race
p2 <- ggplot(df, aes(x = Race)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  labs(title = "Ethnicity/Race Distribution (n=352)",
       y = "Count")

grid.arrange(p1,p2, nrow = 1)
```
```{r}
#Education
p1 <- ggplot(df, aes(x = Education)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 10, vjust = 0.5))+
  labs(title = "Education Distribution (n=352)",
       x = "Education",
       y = "Count")
#Income
p2 <- ggplot(df, aes(x = Income)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 10, vjust = 0.5))+
  labs(title = "Income Distribution (n=352)",
       x = "Income",
       y = "Count")

grid.arrange(p1,p2, nrow = 2)
```

### Checking Condition Success, KM and Positive Affect

Main KM variable of interest
```{r}
ggplot(df, aes(Cond, pKM, fill = Cond)) +
  geom_violin() +
  geom_boxplot(width = 0.1, color = "black", alpha = 0.4) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(title = "Violin Distribution",
       x = "",
       y = "pKM")
```

```{r}
ggplot(df, aes(x = KM_Avg, y = pKM, color = Cond)) +
  geom_jitter(height = .05)
```

Individual KM Aspects
```{r}
p1 <- ggplot(df, aes(KM_P, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "Physiological Signs",
       y = "Density")

p2 <- ggplot(df, aes(KM_CSR, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "CSR Appraisal",
       y = "Density")

p3 <- ggplot(df, aes(KM_M, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "Prosocial Motivation",
       y = "Density")

p4 <- ggplot(df, aes(KM_L, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "Lexical Label",
       y = "Density")

grid.arrange(p1,p2,p3,p4, nrow = 2)
```

Positive affect
```{r}
ggplot(df, aes(PosAff, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "Positive Affect",
       y = "Density")
```

```{r}
p1 <- ggplot(df, aes(ANS_1, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "ANS Time 1",
       y = "Density")

p2 <- ggplot(df, aes(ANS_2, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "ANS Time 2",
       y = "Density")

grid.arrange(p1,p2, nrow = 2)
```

```{r}
p1 <- ggplot(df, aes(RNS_1, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "RNS Time 1",
       y = "Density")

p2 <- ggplot(df, aes(RNS_2, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "RNS Time 2",
       y = "Density")

grid.arrange(p1,p2, nrow = 2)
```
Autonomy Needs
```{r}
df_plot <- df %>% 
  select("Cond", "ANS_1", "ANS_2") %>% 
  pivot_longer(cols = c("ANS_1", "ANS_2"),
               names_to = "Time",
               values_to = "Score")

p1 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

df_plot <- df %>% 
  select("Cond", "ANF_1", "ANF_2") %>% 
  pivot_longer(cols = c("ANF_1", "ANF_2"),
               names_to = "Time",
               values_to = "Score")

p2 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

grid.arrange(p1, p2, nrow = 1)
```


Relatedness Needs
```{r}
df_plot <- df %>% 
  select("Cond", "RNS_1", "RNS_2") %>% 
  pivot_longer(cols = c("RNS_1", "RNS_2"),
               names_to = "Time",
               values_to = "Score")

p1 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

df_plot <- df %>% 
  select("Cond", "RNF_1", "RNF_2") %>% 
  pivot_longer(cols = c("RNF_1", "RNF_2"),
               names_to = "Time",
               values_to = "Score")

p2 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

grid.arrange(p1, p2, nrow = 1)
```


```{r}
df %>% 
  group_by(Cond) %>% 
  summarise_at(vars(RNS_2), list(name = mean))

df %>% 
  group_by(Cond) %>% 
  summarise_at(vars(RNS_1), list(name = mean))
```


Competency Needs
```{r}
df_plot <- df %>% 
  select("Cond", "CNS_1", "CNS_2") %>% 
  pivot_longer(cols = c("CNS_1", "CNS_2"),
               names_to = "Time",
               values_to = "Score")

p1 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

df_plot <- df %>% 
  select("Cond", "CNF_1", "CNF_2") %>% 
  pivot_longer(cols = c("CNF_1", "CNF_2"),
               names_to = "Time",
               values_to = "Score")

p2 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

grid.arrange(p1, p2, nrow = 1)

```

## Variable Correlations
We'll load the hmisc function to get correlation matrices with p-values

First, some descriptive variables 
```{r}
library(Hmisc)
df_cor <- df %>%
  select(Age, EC, Attach_avd, Attach_anx, pKM, PosAff)
rcorr(as.matrix(df_cor))
```
Now to outcome variables
KM
```{r}
df_cor <- df %>%
  select(pKM, KM_P, KM_CSR, KM_L, KM_M)
rcorr(as.matrix(df_cor))
```
```{r}
df_cor <- df %>%
  select(ANF_1, ANF_2, KM_M)
rcorr(as.matrix(df_cor))
```

ARC Needs
```{r}
df_cor <- df %>%
  select(ANS_1, ANF_1, RNS_1, RNF_1, CNS_1, CNF_1,
         ANS_2, ANF_2, RNS_2, RNF_2, CNS_2, CNF_2,
         pKM, PosAff)
rcorr(as.matrix(df_cor))
```

(I think it's actually that KM "does what it does" by accessing and directing PA. By itself the KM variable isn't much, but it seems to really tap the PA side, even more than the amusement. I.e. PA should turn up across the board, no matter the source--if anything, KM cond might still get the bump because it's better at PA than the other stuff)


An optional, Bayesian framing of the correlation table
```{r}
library(correlation)
library(BayesFactor)
correlation(df[, 
               c('Age', 'EC', 'Attach_avd', 'Attach_anx',
                 'ANS_1', 'ANF_1', 'RNS_1', 'RNS_1', 'CNS_1','CNF_1',
                 'ANS_2', 'ANF_2', 'RNS_2', 'RNS_2', 'CNS_2','CNF_2')],
            bayesian = T)
```

## Formating to Long

Let's reshape the data into long format to reflect the multi-time point aspect of the data

##### Autonomy Needs: Pivotting to Long
```{r}
ANS_L <- df %>% select(id, ANS_1_Z, ANS_2_Z) %>% 
  pivot_longer(
    cols = !id,
    names_to = c("AN", "Time"),
    names_sep = (sep = "_"),
    values_to = "ANS_Z"
  ) %>% 
  select(-AN)

ANF_L <- df %>% select(id, ANF_1_Z, ANF_2_Z) %>% 
  pivot_longer(
    cols = !id,
    names_to = c("AN", "Time"),
    names_sep = (sep = "_"),
    values_to = "ANF_Z"
  ) %>% 
  select(-AN)
  
AN_L <- merge(ANS_L, ANF_L, by = c("id", "Time"))
AN_L <- AN_L[order(AN_L$id),]
```
##### Relatedness Needs: Pivotting to Long
```{r}
RNS_L <- df %>% select(id, RNS_1_Z, RNS_2_Z) %>% 
  pivot_longer(
    cols = !id,
    names_to = c("RN", "Time"),
    names_sep = (sep = "_"),
    values_to = "RNS_Z"
  ) %>% 
  select(-RN)

RNF_L <- df %>% select(id, RNF_1_Z, RNF_2_Z) %>% 
  pivot_longer(
    cols = !id,
    names_to = c("RN", "Time"),
    names_sep = (sep = "_"),
    values_to = "RNF_Z"
  ) %>% 
  select(-RN)
  
RN_L <- merge(RNS_L, RNF_L, by = c("id", "Time"))
RN_L <- RN_L[order(RN_L$id),]
```

##### Competency Needs: Pivotting to Long
```{r}
CNS_L <- df %>% select(id, CNS_1_Z, CNS_2_Z) %>% 
  pivot_longer(
    cols = !id,
    names_to = c("CN", "Time"),
    names_sep = (sep = "_"),
    values_to = "CNS_Z"
  ) %>% 
  select(-CN)

CNF_L <- df %>% select(id, CNF_1_Z, CNF_2_Z) %>% 
  pivot_longer(
    cols = !id,
    names_to = c("CN", "Time"),
    names_sep = (sep = "_"),
    values_to = "CNF_Z"
  ) %>% 
  select(-CN)
  
CN_L <- merge(CNS_L, CNF_L, by = c("id", "Time"))
CN_L <- CN_L[order(CN_L$id),]
```
So we've split out the repeated measures variables of df into long format. The df at this point is 352 rows long, and our individual repeated measures are exactly twice that (for two time points)

```{r}
nrow(AN_L) == nrow(RN_L)
nrow(RN_L) == nrow(CN_L)
nrow(df)*2 == nrow(AN_L)
```
```{r}
N_L <- merge(AN_L, RN_L, by = c("id", "Time"))
N_L <- merge(N_L, CN_L, by = c("id", "Time"))
N_L <- N_L[order(N_L$id), ]
N_L
```


Now to merge them together. Quick recap: the data is originally 2-2-1, where only the ARC needs variables are repeated multiple times, specifically twice. Therefore, when putting them together, the data that is measured only once must also show up twice in the dataset to match up with the repeated measures side. I.e. we should have each individual representned twice in the final dataset, but their data (say, Gender) will be the same twice (their gender isn't changing from Time 1 to Time 2), but we do (and only) see change in these ARC need variables.


```{r}
df_L <- df %>%
  slice(rep(1:n(), each = 2)) #repeat every row in the df twice

df_L <- merge(df, N_L, by = c("id"))
df_L <- df_L[order(df_L$id),]
```


## Bayesian Estimation Models


```{r eval=FALSE, warning=FALSE}
library(bmlm)
library(brms)
library(qgraph)
library(bayestestR)
options(mc.cores = parallel::detectCores())
```

```{r}
contrasts(df$Cond) #just confirming our contrast structure for our categorical variable
```

### X->M Pathway

The mediation is a X->M->Y pathway.
Let's focus on the first leg: X -> M. I.e. do the conditions themselves predict pKM and PosAff (our two mediators)

#### Fitting our model
Let's check the names of the priors in the model so that we can properly specify them when running the actual model.
```{r}
get_prior(mvbind(pKM_Z, PosAff_Z) ~ Cond,
    data = df_L)
```

```{r}
fit_M <- brm(mvbind(pKM_Z, PosAff_Z) ~ Cond,
    df_L,
    prior = c(
      set_prior("normal(1.4,.10)", class = "b", resp = c("pKMZ", "PosAffZ")),
      set_prior("normal(1.4,.10)", class = "Intercept", resp = c("pKMZ", "PosAffZ"))
    ),
    warmup = 5000, iter = 10000, chains = 4)
#that "-E" warning is not important--it's a misconfiguration on the developer side (see Stan Forum)
```

#### Plotting model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_M)
dimnames(posterior)

color_scheme_set("viridis")

## Autocorrelation Plots
```

##### Chain Mixing Plots
```{r}
mcmc_trace(posterior,pars = c("b_pKMZ_Intercept","b_PosAffZ_Intercept"),
           facet_args = list(ncol = 1))
```

```{r}
mcmc_trace(posterior,pars = c("b_pKMZ_CondAmuse","b_pKMZ_CondKM", "b_PosAffZ_CondAmuse", "b_PosAffZ_CondKM"),
           facet_args = list(ncol = 2))
```

```{r}
mcmc_trace(posterior,pars = c("sigma_pKMZ","sigma_PosAffZ"),
           facet_args = list(ncol = 1))
```

##### Autocorrelation Plots
```{r}
mcmc_acf(posterior,pars = c("b_pKMZ_Intercept","b_PosAffZ_Intercept"))
```

```{r}
mcmc_acf(posterior,pars = c("b_pKMZ_CondAmuse","b_pKMZ_CondKM", "b_PosAffZ_CondAmuse", "b_PosAffZ_CondKM"))
```

```{r}
mcmc_acf(posterior,pars = c("sigma_pKMZ","sigma_PosAffZ"))
```


#### Summaries of the Model
```{r}
summary(fit_M)
```
Remember, all of these effects are the **medians** of their respective distributions.

Another, perhaps easier to see though less detailed summary
```{r}
describe_posterior(fit_M)
```

From Vehtari, Gelman, Simpson, Carpenter, Burkner (2019), we know that convergence of the MCs is not necessarily the same across the entire parameter space. Our chain plots show convergence visually, but we can also evaluate convergence in terms of how much stable sampling we were able to achieve in both the "main" part of the distribution and at the outer (typically less stable) ends.
"Bulk_ESS" is the term Bayesians have previously called "Effective Sample Size." It means the number of effective, i.e. independent, samples in the center of the poterior distribution (i.e. make up the "bulk" of the posterior). "Tail_ESS" is consequently about the tails of that distribution (5%-95% quantiles), allowing us to see how many effective samples are in the outer sides of the distribution. Put together, we can get a clearer picture of parameter stability across the distribution. 

#### Plotting Model Posteriors
```{r}
mcmc_areas(
  posterior,
  pars = c("b_pKMZ_Intercept", "b_PosAffZ_Intercept",
           "b_pKMZ_CondAmuse", "b_pKMZ_CondKM", "b_PosAffZ_CondAmuse","b_PosAffZ_CondKM",
           "sigma_pKMZ", "sigma_PosAffZ"),
  prob = 0.95,
  prob_outer = 0.99,
  point_est = "median"
)
```

```{r}
mcmc_intervals(
  posterior,
  pars = c("b_pKMZ_Intercept", "b_PosAffZ_Intercept",
           "b_pKMZ_CondAmuse", "b_pKMZ_CondKM", "b_PosAffZ_CondAmuse","b_PosAffZ_CondKM",
           "sigma_pKMZ", "sigma_PosAffZ"),
  prob = 0.95,
  prob_outer = 0.99,
  point_est = "mean"
)
```

Marginal (All Chains) Posterior Distributions
```{r}
mcmc_dens(
  posterior,
  pars = c("b_pKMZ_CondAmuse", "b_pKMZ_CondKM", "b_PosAffZ_CondAmuse","b_PosAffZ_CondKM")
)
```

Trying to see direct ROPE numbers
```{r}
describe_posterior(fit_M) #note, multivariate is not supported yet with the ROPE function in BayestestR
```
Looks like we won't be able to see direct ROPE metrics using these multivariate models yet. Can still evaluate the main benchmark (does the CI cross +/- .05 or not) from the posterior estimates and CI, but won't be able to measure specific percentage this way.


### Autonomy Model
We'll start with autonomy. We're again using multivariate functions here to map both autonomy satisfaction and frustration at the same time. This side of the mediation does have repeated measures, so we'll use a multi-level model formulation. Since our outcomes are highly correlated, we'll also be setting the random intercepts to correlate between each outcome.  

#### Fitting our model
```{r}
get_prior(mvbind(ANS_Z, ANF_Z) ~ Cond + PosAff_Z + pKM_Z + Time + (1|p|id),
    data = df_L)
```

```{r}
fit_A <- brm(mvbind(ANS_Z, ANF_Z) ~ Cond + PosAff_Z + pKM_Z + Time + (1|p|id),
    data = df_L,
    prior = c(
      set_prior("normal(0,2)", class = "b", coef = "pKM_Z", resp = c("ANSZ", "ANFZ")),
      set_prior("normal(.10,1)", class = "b", coef = "PosAff_Z", resp = "ANSZ"),
      set_prior("normal(-.10,1)", class = "b", coef = "PosAff_Z", resp = "ANFZ"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse", resp = c("ANSZ","ANFZ")),
      set_prior("normal(0,2)", class = "b", coef = "CondKM", resp = c("ANSZ","ANFZ")),
      set_prior("normal(0,2)", class = "Intercept", resp = c("ANSZ", "ANFZ"))
    ),
    warmup = 5000, iter = 10000, chains = 4)

#that "-E" warning is not important--it's a misconfiguration on the developer side (see Stan Forum)
```


#### Plotting our model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_A)
dimnames(posterior)$variable[1:18]

color_scheme_set("viridis")
```
##### Chain Mixing Plots
```{r}
mcmc_trace(posterior,pars = c("b_ANSZ_Intercept","b_ANFZ_Intercept"),
           facet_args = list(ncol = 1))
```

```{r}
mcmc_trace(posterior,pars = c("b_ANSZ_CondAmuse","b_ANSZ_CondKM", "b_ANSZ_PosAff_Z", "b_ANSZ_pKM_Z"),
           facet_args = list(ncol = 2))
```

```{r}
mcmc_trace(posterior,pars = c("b_ANFZ_CondAmuse","b_ANFZ_CondKM", "b_ANFZ_PosAff_Z", "b_ANFZ_pKM_Z"),
           facet_args = list(ncol = 2))
```

```{r}
mcmc_trace(posterior,pars = c("sigma_ANSZ","sigma_ANFZ"),
           facet_args = list(ncol = 1))
```

##### Autocorrelation Plots
```{r}
mcmc_acf(posterior,pars = c("b_ANSZ_Intercept","b_ANFZ_Intercept"))
```

```{r}
mcmc_acf(posterior,pars = c("b_ANSZ_CondAmuse","b_ANSZ_CondKM", "b_ANSZ_PosAff_Z", "b_ANSZ_pKM_Z"))
```

```{r}
mcmc_acf(posterior,pars = c("b_ANFZ_CondAmuse","b_ANFZ_CondKM", "b_ANFZ_PosAff_Z", "b_ANFZ_pKM_Z"))
```

```{r}
mcmc_acf(posterior,pars = c("sigma_ANSZ","sigma_ANFZ"))
```


#### Summaries of the Model
```{r}
summary(fit_A)
```
Remember, all of these effects are the **medians** of their respective distributions.

Another, perhaps easier to see though less detailed summary
```{r}
describe_posterior(fit_A)
```
We see that PosAffect has appreciable effects on both ANF and ANS in the directions you'd expect (feel good, feel higher ANS and lower ANS).
We also see that KM does have an effect on ANF--where higher KM **increases** Autonomy frustration-- but does nothing to autonomy satisfaction. We might be seeing a reaction to emotional content--a "don't play with my emotions/being-state" that comes from the videso or perhaps just a nature of the KM emotion itself (perhaps culture dependent? UK/Western cultures I think are less culturally accepting of emotionality--though given this is a generally positive emotion, this culture-specificity might not be sufficient)




Do I need to model time earlier in the model equation?
```{r}
fit_A2 <- brm(mvbind(ANS_Z, ANF_Z) ~ Time + Cond + PosAff_Z + pKM_Z + (1|p|id),
    data = df_L,
    prior = c(
      set_prior("normal(0,2)", class = "b", coef = "pKM_Z", resp = c("ANSZ", "ANFZ")),
      set_prior("normal(.10,1)", class = "b", coef = "PosAff_Z", resp = "ANSZ"),
      set_prior("normal(-.10,1)", class = "b", coef = "PosAff_Z", resp = "ANFZ"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse", resp = c("ANSZ","ANFZ")),
      set_prior("normal(0,2)", class = "b", coef = "CondKM", resp = c("ANSZ","ANFZ")),
      set_prior("normal(0,2)", class = "Intercept", resp = c("ANSZ", "ANFZ"))
    ),
    warmup = 5000, iter = 10000, chains = 4)
```

```{r}
describe_posterior(fit_A2)
```
Nope, formula inclusion order does not seem to matter--effects are all turning out basically the 

### Relatedness Model

#### Fitting our model
```{r}
get_prior(mvbind(RNS_Z, RNF_Z) ~ Cond + PosAff_Z + pKM_Z + Time + (1|p|id),
    data = df_L)
```

```{r}
fit_R <- brm(mvbind(RNS_Z, RNF_Z) ~ Cond + PosAff_Z + pKM_Z + Time + (1|p|id),
    data = df_L,
    prior = c(
      set_prior("normal(.09,.03)", class = "b", coef = "pKM_Z", resp = "RNSZ"),
      set_prior("normal(-.05,.02)", class = "b", coef = "pKM_Z", resp = "RNFZ"),
      set_prior("normal(.10,1)", class = "b", coef = "PosAff_Z", resp = "RNSZ"),
      set_prior("normal(-.10,1)", class = "b", coef = "PosAff_Z", resp = "RNFZ"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse", resp = c("RNSZ","RNFZ")),
      set_prior("normal(0,2)", class = "b", coef = "CondKM", resp = c("RNSZ","RNFZ")),
      set_prior("normal(0,2)", class = "Intercept", resp = c("RNSZ", "RNFZ"))
    ),
    warmup = 5000, iter = 10000, chains = 4)

#that "-E" warning is not important--it's a misconfiguration on the developer side (see Stan Forum)
```

#### Plotting our model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_R)
dimnames(posterior)$variable[1:18]

color_scheme_set("viridis")
```

##### Chain Mixing Plots
```{r}
mcmc_trace(posterior,pars = c("b_RNSZ_Intercept","b_RNFZ_Intercept"),
           facet_args = list(ncol = 1))
```

```{r}
mcmc_trace(posterior,pars = c("b_RNSZ_CondAmuse","b_RNSZ_CondKM", "b_RNSZ_PosAff_Z", "b_RNSZ_pKM_Z"),
           facet_args = list(ncol = 2))
```

```{r}
mcmc_trace(posterior,pars = c("b_RNFZ_CondAmuse","b_RNFZ_CondKM", "b_RNFZ_PosAff_Z", "b_RNFZ_pKM_Z"),
           facet_args = list(ncol = 2))
```

```{r}
mcmc_trace(posterior,pars = c("sigma_RNSZ","sigma_RNFZ"),
           facet_args = list(ncol = 1))
```

##### Autocorrelation Plots
```{r}
mcmc_acf(posterior,pars = c("b_RNSZ_Intercept","b_RNFZ_Intercept"))
```

```{r}
mcmc_acf(posterior,pars = c("b_RNSZ_CondAmuse","b_RNSZ_CondKM", "b_RNSZ_PosAff_Z", "b_RNSZ_pKM_Z"))
```

```{r}
mcmc_acf(posterior,pars = c("b_RNFZ_CondAmuse","b_RNFZ_CondKM", "b_RNFZ_PosAff_Z", "b_RNFZ_pKM_Z"))
```

```{r}
mcmc_acf(posterior,pars = c("sigma_RNSZ","sigma_RNFZ"))
```


#### Summaries of the Model ####
```{r}
summary(fit_R)
```

```{r}
describe_posterior(fit_R)
```
KM once again has basically a zero effect on RNF, but once again we see a slight positive affect on RNS (EVEN without the PA included). I bet that this effect goes up even more if considering the PA aspect in the KM calculation.
Also, we see some remaining variance "juice" from the conditions that are not being picked up by anything.
RNF
1) CondKM: KM condition folks have a slightly higher RNF than the other conditions even with the specific PA and KM variance is explained out. There is some unexplained variance here that suggests there is something in the **opposite** direction of KM (having little to no effect on RNS) within the KM condition. E.g. a tinge of jealousy? Or perhaps a biased original sample that randomization didn't smooth out--do we see a difference in RNF between the groups at the outset?
RNS
2) CondKM: KM condition folks have a slightly lower RNS than the other conditions once the specific PA and KM variance is explained out. There is some unexplained variance here that suggests something in the **opposite** direction of KM's increaseing of RN satisfaction within the the KM condition


### Competency Model

#### Fitting our model
```{r}
get_prior(mvbind(CNS_Z, CNF_Z) ~ Cond + PosAff_Z + pKM_Z + Time + (1|p|id),
    data = df_L)
```

```{r}
fit_C <- brm(mvbind(CNS_Z, CNF_Z) ~ Cond + PosAff_Z + pKM_Z + Time + (1|p|id),
    data = df_L,
    prior = c(
      set_prior("normal(0,2)", class = "b", coef = "pKM_Z", resp = "CNSZ"),
      set_prior("normal(0,2)", class = "b", coef = "pKM_Z", resp = "CNFZ"),
      set_prior("normal(.10,1)", class = "b", coef = "PosAff_Z", resp = "CNSZ"),
      set_prior("normal(-.10,1)", class = "b", coef = "PosAff_Z", resp = "CNFZ"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse", resp = c("CNSZ","CNFZ")),
      set_prior("normal(0,2)", class = "b", coef = "CondKM", resp = c("CNSZ","CNFZ")),
      set_prior("normal(0,2)", class = "Intercept", resp = c("CNSZ", "CNFZ"))
    ),
    warmup = 5000, iter = 10000, chains = 4)

#that "-E" warning is not important--it's a misconfiguration on the developer side (see Stan Forum)
```

#### Plotting our model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_C)
dimnames(posterior)$variable[1:18]

color_scheme_set("viridis")
```

##### Chain Mixing Plots
```{r}
## Chain Mixing Plots
mcmc_trace(posterior,pars = c("b_CNSZ_Intercept","b_CNFZ_Intercept"),
           facet_args = list(ncol = 1))
```

```{r}
mcmc_trace(posterior,pars = c("b_CNSZ_CondAmuse","b_CNSZ_CondKM", "b_CNSZ_PosAff_Z", "b_CNSZ_pKM_Z"),
           facet_args = list(ncol = 2))
```

```{r}
mcmc_trace(posterior,pars = c("b_CNFZ_CondAmuse","b_CNFZ_CondKM", "b_CNFZ_PosAff_Z", "b_CNFZ_pKM_Z"),
           facet_args = list(ncol = 2))
```

```{r}
mcmc_trace(posterior,pars = c("sigma_CNSZ","sigma_CNFZ"),
           facet_args = list(ncol = 1))
```

##### Autocorrelation Plots
```{r}
## Autocorrelation Plots
mcmc_acf(posterior,pars = c("b_CNSZ_Intercept","b_CNFZ_Intercept"))
```

```{r}
mcmc_acf(posterior,pars = c("b_CNSZ_CondAmuse","b_CNSZ_CondKM", "b_CNSZ_PosAff_Z", "b_CNSZ_pKM_Z"))
```

```{r}
mcmc_acf(posterior,pars = c("b_CNFZ_CondAmuse","b_CNFZ_CondKM", "b_CNFZ_PosAff_Z", "b_CNFZ_pKM_Z"))
```

```{r}
mcmc_acf(posterior,pars = c("sigma_CNSZ","sigma_CNFZ"))
```

#### Summaries of the Model
```{r}
summary(fit_C)
```

```{r}
describe_posterior(fit_C)
```

Very similar to Autonomy needs, we see that PosAffect has appreciable effects on both ANF and ANS in the directions you'd expect (feel good, feel higher CNS and lower CNF).
Again very similar to Autonomy needs, we also see that KM does have an effect on ANF--where higher KM **increases** Competency frustration-- AND also seems to reduce competency satisfaction as well (the range of effects here cross zero in the latter though, so less confident here). Point though, is that KM seems to be having an overall negative effect on Competency--increasing frustration and *maybe* decreasing competency satisfaction. Again potentially due to an emotional and/or cultural favoritism towards "reigning in" emotions.

The effect of KM condition is mostly wiped out with Frustration, though some unexplained variance is left on the table with Satisfaction.

## Summary of Results

### Visualizing
```{r}
library(diagram)
data <- c(0, "'.47*'", 0,
          0, 0, 0, 
          "'.36*'", "'.33* (.16)'", 0)
M<- matrix (nrow=3, ncol=3, byrow = TRUE, data=data)
plot<- plotmat (M, pos=c(1,2), 
                name= c( "Math self-efficacy","Math ability", "Interest in the math major"), 
                box.type = "rect", box.size = 0.12, box.prop=0.5,  curve=0)
```

```{r}
library(diagram)
names <- c("pKM", "D1", "Sat", "D2", "Frus", "PA")
M <- matrix(nrow = 6, ncol = 6, byrow = T,
            data = c(0, "A", 0, "B", 0, 0,
                     0,  0,  0,  0,  0, 0,
                     "I","E",0, "F", 0, "K",
                     0,  0,  0,  0,  0,  0,
                     "J","G",0, "H", 0, "L",
                     0, "C", 0, "D", 0, 0),
            dimnames = list(c("pKM", "D1", "Sat", "D2", "Frust", "PA"), 
                            c("pKM", "D1", "Sat", "D2", "Frust", "PA")))

plotmat(M, pos = c(1,2,2,1), relsize = 1.08,
        curve = 0, name = names,
        cex.txt = .8,
        lwd = 1, box.lwd = 2,
        box.type = "square", box.size = 0.07, box.prop = .5)


```

ANS by pKM
```{r}
ggMarginal(
  ggplot(df_L, aes(x=pKM_Z, y = ANS_Z, color = Cond)) +
    geom_point() +
    geom_smooth(method = lm)+
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "ANS Z-Scored"),
  groupColour = T, groupFill = T)
```
ANF
```{r}
ggMarginal(
  ggplot(df_L, aes(x=pKM_Z, y = ANF_Z, color = Cond)) +
    geom_point() +
    geom_smooth(method = lm) +
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "ANF Z-Scored"),
groupColour = T, groupFill = T)
```
RNS
```{r}
ggMarginal(
    ggplot(df_L, aes(x=pKM_Z, y = RNS_Z, color = Cond)) +
      geom_point() +
      geom_smooth(method = lm)+
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "RNS Z-Scored"),
  groupColour = TRUE, groupFill = TRUE)
```
RNF
```{r}
ggMarginal(
    ggplot(df_L, aes(x=pKM_Z, y = RNF_Z, color = Cond)) +
      geom_point() +
      geom_smooth(method = lm)+
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "RNF Z-Scored"),
  groupColour = TRUE, groupFill = TRUE)
```

CNS
```{r}
ggMarginal(
    ggplot(df_L, aes(x=pKM_Z, y = CNS_Z, color = Cond)) +
      geom_point() +
      geom_smooth(method = lm)+
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "CNS Z-Scored"),
  groupColour = TRUE, groupFill = TRUE)
```
CNF
```{r}
ggMarginal(
    ggplot(df_L, aes(x=pKM_Z, y = CNF_Z, color = Cond)) +
      geom_point() +
      geom_smooth(method = lm)+
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "CNF Z-Scored"),
  groupColour = TRUE, groupFill = TRUE)
```

Mediator (i.e. Did the Conditions work)
```{r}
describe_posterior(fit_M)
#summary(fit_M) more detailed version
```
##### pKMZ ##### 
It appears that the KM condition was very successful in instilling pKM. The Amusement condition had an effect insofar as it cancelled out the low scores of the neutral (intercept) condition. I.e. Neutral condition folks had very low KM scores (-.67 Zs below the overall average), Amusement condition folks had middling KM scores (-.67 + .67 = 0 Zs), KM condition folks had higher KM scores (-.67 + 1.76 = ~1.09)
#### Positive Affect #####
The Amusement condition was successful in instilling higher PA, however the KM condition did nearly as well too--perhaps even a bit better than the Amusement condition. The Neutral condition folks had lower PA scores.
Suggestive already that the KM videos, being of human relationships, are even more potent at instilling good feelings than of simple "comedic" events.

Autonomy
```{r}
describe_posterior(fit_A)
#summary(fit_A)
```
##### ANF #####
Neutral condition had a zero effect on ANF. The KM and Amuse conditions themselves too had little effect. PA had a negative effect on ANF, such that higher PA was associated with lower ANF (CI well outside ROPE). pKM (remember, a "PA"-less KM variable) had a positive effect on ANF, such that higher pKM scores was associated with higher ANF (CI well outside ROPE). 
This is suggestive that KM may have some element of increasing people's feelings of self-"dis-control", which is contrast to the typical effect of "feeling good" reducing such feelings of "dis-control." Considering a UK/Western sample, we may be seeing an effect of cultural expectations regarding emotional control. However, considering PA and pKM have effects in the opposite direction, this is a "PA"-less KM variable effect may *normally* be flattened out when including the PA aspect as per usual KM formulation. I.e. we may be seeing an effect not usually seen by other KM research that has always usually considered these together.

##### ANS #####
Neutral condition had a positive effect on ANS. The Amuse condition had little to no effect on ANS (.16 + -.17 = ~-.01). The KM condition had a small negative effect on ANS (.16+-.28 = ~-.12). PA had a positive effect on ANS, such that higher PA was associated with higher ANS. pKM had little to no effect on ANS (median estimate within ROPE, 95% CI crossing zero).
PA seems to have an effect on ANS, however "PA-less" KM does not. I.e. to the extent that KM has *any* effect on ANS, it is entirely driven by the fact that KM is usually considered with PA. Poignant emotions of connectedness to others does not seem to satisfy feelings of autonomy, perhaps because the emotion is a poignant reminder of communality--which may be mistaken for, or intermixed with, signals of dependency.

TLDR: KM, sans it's PA feature, makes people feel less autonomous rather than more. (at least in this Western sample)

Relatedness
```{r}
describe_posterior(fit_R)
#summary(fit_R)
```
##### RNF #####
The Neutral condition had a near zero effect on RNF scores. The Amusement condition was similarly small, though perhaps slightly negative (wide CI, crossing zero though). The KM condition had a positive effect on RNF scores (though complicated by another wide CI, crossing zero as well). PA had a negative effect on RNF, such that higher PA was associated with lower RNF (CI far outside ROPE). KM had a near zero effect on RNF (largely within ROPE).
Much like our last study, we see that KM has a negligible effect on RNF and any effect that *may* emerge from it would likely be largely driven by PA. PA is otherwise functioning as theoretically expected.

##### RNS #####
The neutral condition has a positive effect on RNS scores. The Amusement condition, and KM condition even moreso, were lower by comparison (remember these are in terms of model intercepts, accounting alongside the specific effects that are modeled, not exactly "means"--see earlier figure how all 3 conditions had largely the same means at time 1). PA had a positive effect on RNS, such that higher PA was associated with higher RNS (CI well outside ROPE). KM had a positive effect on RNS, such that higher KM was associated with higher RNS (CI outside of ROPE).
This is good replication of our last study--"PA-less" KM has nearly the exact same effect as seen in our last study, though a tiny bit more removed from the ROPE. Once again, we see PA working as theoretically expected. But the crucial thing for us is that KM, even without the PA aspect, retains some effect on RNS, suggesting that KM is not entirely synonymous (or replacable) with PA.
Competency
```{r}
describe_posterior(fit_C)
#summary(fit_C)
```
##### CNF #####
The Neutral condition had no effect on CNF scores. The Amusement condition had a slight positive effect on CNF. The KM condition had a near-zero effect on CNF. PA had a negative effect on CNF, such that higher PA was associated with lower CNF (CI well outside ROPE). KM had a positive effect on CNF, such that higher KM scores were associated with higher CNF (CI well outside ROPE). 
Similar to autonomy, we see a divergence in PA and KM effects. PA is functioning as theoretically expected. "PA-less" KM seems to increase feelings of incompetence, perhaps an indicator again of "emotional takeover." Or, in terms of KM theory, this may be very prosocially driven emotional development--this could be a driver of KM's theoretical prosocial motivation, a way to reduce competence frustration. It should be noted that frustration is not the mere absence of satisfaction--this is more than simply not feeling competent, but the negative feelingt that comes from not feeling competent. I.e. KM increasing CNF may fit into KM's anthropological theory of promoting extension and commitment to a community.

##### CNS #####
The Neutral condition had little to no  effect on CNS scores. The Amusement condition had little to no effect on CNS. The KM condition had little to no effect on CNS, though perhaps negative effect (wide CI, crossing zero still). PA had a positive effect on CNS, such that higher PA was associated with higher CNS (CI well outside ROPE). KM had a near-zero, negative effect on CNS such that higher KM was associated with lower CNS (estimate negative, but wide CI crossing zero and almost entirely encompassing ROPE).
Again, PA is functioning as theoretically expected. "PA-less" KM has a very noisy effect here, such that any conclusions in one way or the other is hard. If anything, we'd say KM reduces competency satisfaction--which is line with the aforementioned anthropological theorizing of KM in terms of social promotion and community we see in CNF--however these numbers are too messy for me to be confident.

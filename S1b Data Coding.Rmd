---
title: "S1b Data Code"
author: "Ian Hajnosz"
date: "3/17/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First, loading in helpful the packages
```{r}
library(dplyr)
library(tidyverse)
library(readr)
library(ggplot2)
library(viridis)
library(gridExtra)
library(bmlm)
library(brms)
library(qgraph)
library(bayestestR)
library(ggExtra)
library(Hmisc)
library(bayesplot)
options(mc.cores = parallel::detectCores())
set.seed(123)
```
## Data Entry & Cleaning

### Data Loading
Now to load in the data. I'm saving an "anchor" dataframe (df) as a reference point to the original data. We'll iterate using the df dataframe from now on.
```{r}
df <- df_anchor <- read_csv("Ian+Study+1b_March+17,+2022_09.18.csv")
```

### Data Cleaning

#### Removing Unnecessary Data
Removing Unnecessary columns. This includes removing  participated metadata Qualtrics automatically collects in their surveys, as well as most of the "DO" variables--these are the scale and item ordering within each survey block. Items were randomized within their respective scale, and scales were randomly presented within their given survey block in the survey flow. We can see that randomization did work, but otherwise these aren't helpful for us now.
Note: We do keep one "DO" variable called, FL_5_DO--this column names us the video the participant viewed in the survey. We'll use this variable to double check participant attentiveness later on
```{r}
df <- select(df,
       -(StartDate:Progress)) #removing participant metadata columns (unnecessary variables)

df <- select(df,
       -(Finished:UserLanguage)) #removing participant metadata columns (unnecessary variables)

df <- df[-c(1,2),] #removing participant metadata rows (first two rows are metadata)

df <- select(df,
       -c(Aut1_DO, Rel1_DO, Comp1_DO, EC_DO, Attach_DO,KM_P_DO, KM_CSR_DO, KM_M_DO, KM_L_DO,PANAS_DO, Aut2_DO, Rel2_DO, Comp2_DO, Vid_SelfRep_DO, FL_3_DO, FL_31_DO, FL_33_DO, SC0)) # removing unnecessary display ordering columns
```

#### Reference ID Variable
Now we can creating a separate ID variable, just for reference sake
```{r}
df$id <- 1:nrow(df)
df <- df %>% 
  select(id, everything()) #moving the id variable to the front of the df
```

#### Renaming Columns
We have some columns with unhelpful names. Let's change that. We'll also change that FL_5_DO from earlier into a more recognizable and helpful variable name.

```{r}
df <- rename(df,
       Neutral_Timer = 'Timer_Neutral_Page Submit',
       KM_Timer = 'Timer_KM_Page Submit',
       Amuse_Timer = 'Timer_Amuse_Page Submit',
       Cond = FL_5_DO,
       Vid_Issue_Text = Vid_Issue_2_TEXT,
       Race_Text = Race_10_TEXT,
       SexualOr_Text = SexualOr_6_TEXT,
       Age = Age_1,
       Survey_Duration = `Duration (in seconds)`)
```

#### Recoding Responses
Let's try to simplify some of the character responses in our new Cond variable into numerics for easier organization.
We can also recode answers to that attention check item. Participants were instructed to only select "Not at all" which is also coded as 0. Therefore, any participant who responded as 0 passed, any other response is an attention check fail.
```{r}
df <- mutate(df, 
             Cond = recode(Cond,
                'VideoCondition1"ThaiMedicine"Zickfeldetal.2019' = "KM",
                'VideoNeutral1"CleanHardwoodFloors"(Riveraetal.,2019)' = "Neutral",
                'VideoCondition2"MrBean"Zickfeldetal.,2019' = "Amuse"))

table(df$AttCheck_1, exclude = NULL)
df$AttCheck_1 <- ifelse(df$AttCheck_1 == 0,
                        "Pass",
                        "Fail")
table(df$AttCheck_1)#checking ifelse worked properly

```

#### Checing Variable Typing
Now let's make sure the variables are the correct type of data. I.e. that numeric data are being treated as numeric, characters are factors etc.

Numeric Data
```{r}
df$Survey_Duration <- as.numeric(df$Survey_Duration)
df[, c(4:71, 73:113)] <- sapply(df[, c(4:71, 73:113)], as.numeric) #just choosing all the columns by index to be made numeric
df$Age <- as.numeric(df$Age)
```

Factor Data
```{r}
#Consent
table(df$Consent)#only "1"s in here, so only a single level to label
df$Consent <- factor(df$Consent, labels = "Consent")

#Video Self Report
table(df$Vid_SelfRep) #based on the survey, 2 = Neutral Video description, 3 = KM Video description, 6 = Amusement Video Description. All other responses were fake video descriptions
df$Vid_SelfRep <- factor(df$Vid_SelfRep, labels = c(
  "Fake1",
  "Neutral",
  "KM",
  "Amuse",
  "Fake7"
))
table(df$Vid_SelfRep)#Video self report changes line up with original

#Video Audio
table(df$Vid_Audio) #based on the survey, 1 = No audio, 2 = Yes audio
df$Vid_Audio <- factor(df$Vid_Audio, labels = c(
  "No",
  "Yes"
))
table(df$Vid_Audio)

#Video Issues
table(df$Vid_Issue)#Based on survey, 1= No, 2 = Yes
df$Vid_Issue <- factor(df$Vid_Issue, labels = c(
  "No",
  "Yes"
))
table(df$Vid_Issue)

#Video Issues Character String
summary(df$Vid_Issue_Text)#can keep as a character string
table(df$Vid_Issue_Text) #just to see spread of issues
df %>% 
  filter(!is.na(Vid_Issue_Text))#Just to see the exact participants with video issues

#Previous Experience with Video
table(df$Vid_PrevExp)#Based on survey, 1 = No, 2 = Yes
df$Vid_PrevExp <- factor(df$Vid_PrevExp, labels = c(
  "No",
  "Yes"
))
table(df$Vid_PrevExp)

#Gender
table(df$Gender) #Based on survey, 0 = Female, 1 = Male, 2 = Trans Female, 3 = Trans Male(unrepresented in data), 4 = Nonbinary, 5 = Bigender, 6 = Agender

df$Gender <- factor(df$Gender, labels = c(
  "Female",
  "Male",
  "Trans Female",
  "Nonbinary",
  "Bigender",
  "Agender"
))
table(df$Gender)

#Gender, Write-In
table(df$Gender_7_TEXT)# No write-in gender responses

#Race
table(df$Race) #Based on survey, 0 = White, 1 = Black, African, Caribbean, 2 = Hispanic, Latino, Chicano, 3 = East Asian, 4 = South Asian, 5 = Southeast Asian, 6 = West Asian (unrepresented in data), 7 = Middle Eastern, Arab, 8 = Aboriginal, Indigenous, Native (unrepresented in data), 9 = Mixed or Multiple Ethnic Groups, 10 = Write-in
df$Race <- factor(df$Race, labels = c(
  "White, Caucasian, Anglo",
  "Black, African, Caribbean",
  "Other Write-In",
  "Hispanic, Latino, Chicano",
  "East Asian",
  "South Asian",
  "Southeast Asian",
  "Middle Eastern, Arab",
  "Mixed or Multiple Groups"
))
table(df$Race)

#Race, Write-In
table(df$Race_Text)
df$Race[df$Race_Text == "White and Hispanic"] <- "Mixed or Multiple Groups"
df$Race[df$Race_Text == "White, european"] <- "White, Caucasian, Anglo"

#Education
table(df$Education) # Based on survey, 0 = "GCSE, O-Levels, or Standard Grades", 1 = "A-Levels or Highers/Advanced Highers", 2 = "Vocational degree (e.g., SVQ, HNC, HND)", 3 = "Undergraduate degree (e.g., BSc, BA)", 4 = "Master's degree (e.g., MSc, MPhil)", 5 = "PhD, PsyD", 6 = "Other advanced or professional degree (e.g., MD, JD)"
df$Education <- factor(df$Education, labels = c(
  "GCSE, O-Levels, or Standard Grades",
  "A-Levels or Highers/Advanced Highers",
  "Vocational degree (e.g., SVQ, HNC, HND)",
  "Undergraduate degree (e.g., BSc, BA)",
  "Master's degree (e.g., MSc, MPhil)",
  "PhD, PsyD", 
  "Other advanced or professional degree (e.g., MD, JD)"
))
table(df$Education)

#Student
table(df$Student) # Based on survey, 0 = No, 1 = Yes
df$Student <- factor(df$Student, labels = c(
  "No",
  "Yes"
))
table(df$Student)

#Employed
table(df$Employed) # Based on survey, 0 = No, 1 = Part-time, 2 = Full-time
df$Employed <- factor(df$Employed, labels = c(
  "No",
  "Part-time",
  "Full-time"
))
table(df$Employed)

#Income
table(df$Income) # Based on survey, 0 = £0-£12,500, 1 = £12,501-£14,549, 2 = £14,550-£24,944, 3 = £24,945-£43,430, 4 = £43,431-£150,000, 5 = £150,001+
df$Income <- factor(df$Income, labels = c(
  "£0-£12,500",
  "12,501-£14,549",
  "£14,550-£24,944",
  "£24,945-£43,430",
  "£43,431-£150,000",
  "£150,001+"
))
table(df$Income)

#Sexual Orientation
table(df$SexualOr) # Based on survey, 0 = Heterosexual, Straight, 1 = Gay, 2 = Lesbian, 3 = Queer, 4 = Bisexual, Pansexual, 5 = Demisexual, 6 = Asexual, 7 = Other Write-In (not represented in these data)
df$SexualOr <- factor(df$SexualOr, labels = c(
  "Heterosexual, Straight",
  "Gay",
  "Lesbian",
  "Queer",
  "Bisexual, Pansexual",
  "Demisexual",
  "Asexual",
  "Other Write-In"
))
table(df$SexualOr)

#Sexual Orientation, Write-Ins
table(df$SexualOr_Text) #no corrections applicable

#Condition, Re-leveling for dummy coding
table(df$Cond)
df$Cond <- factor(df$Cond)
contrasts(df$Cond) # "Amuse", alphabetically first, is the current reference grouup
df$Cond <- fct_relevel(df$Cond, "Neutral") #re-leveling for reference group
```
Now to do some broad checks across the variables to see if any outliers, impossible ratings appear etc.
```{r}
summary(df)
```
### Pre-Processing
Now that the variables are entered correctly, we can go about making the appropriate transformations, reverse-codings etc. on those variables

#### Reverse-Codings and collating scores
For reverse coding, we can use the equation: Reversed score = (total available responses in scale + 1) - Reported Score
This way, in a 7-item, 1-7 coding scheme, 1s become 7s ((7+1)-1 = 7), 2s become 6s ((7+1)-2 = 6) etc.

T1 Autonomy Satisfaction & Frustration
```{r}
#Aut Sat items: 1, 2, 3, 4
df$ANS_1 <- rowMeans(df[,c("Aut1S_1", "Aut1S_2", "Aut1S_3", "Aut1S_4")], na.rm = T)

#Aut Frus items: 5, 6, 7, 8
df$ANF_1 <- rowMeans(df[,c("Aut1F_5", "Aut1F_6", "Aut1F_7", "Aut1F_8")], na.rm = T)
```

T1 Relatedness Satisfaction & Frustration
```{r}
#Rel Sat items: 1, 2, 3, 4
df$RNS_1 <- rowMeans(df[,c("Rel1S_1", "Rel1S_2", "Rel1S_3", "Rel1S_4")], na.rm = T)

#Rel Frus itmes: 5, 6, 7, 8
df$RNF_1 <- rowMeans(df[,c("Rel1F_5", "Rel1F_6", "Rel1F_7", "Rel1F_8")], na.rm = T)
```

T1 Competency Satisfaction & Frustration
```{r}
#Comp Sat items: 1, 2, 3, 4
df$CNS_1 <- rowMeans(df[,c("Comp1S_1", "Comp1S_2", "Comp1S_3", "Comp1S_4")], na.rm = T)

#Comp Frus itmes: 5, 6, 7, 8
df$CNF_1 <- rowMeans(df[,c("Comp1F_5", "Comp1F_6", "Comp1F_7", "Comp1F_8")], na.rm = T)
```
Empathic Concern
Note, that this has a zero-point in it's scale. This means the reverse score equation is 
Reversed score = (total available responses in scale - 1) - Reported Score.
This way, in a 5-item, 0-4 coding scheme, 0s become (5-1)-0 = 4), 1s become (5-1)-1 = 3 etc.
```{r}
summary(df$EC_1)#Correctly on the 0-4 scale

#EC items with reversed coding (r): 1, 2R, 3, 4R, 5R, 6, 7
df$EC_2R <- 4 - df$EC_2
df$EC_4R <- 4 - df$EC_4
df$EC_5R <- 4 - df$EC_5
df$EC <- rowMeans(df[, c("EC_1", "EC_2R", "EC_3", "EC_4R", "EC_5R", "EC_6", "EC_7")], na.rm = T)

```

General/Global Attachment: Avoidance and Anxiety
Note, for reverse coding without a zero point, we can use the equation:
Reversed score = (total available responses in scale + 1) - Reported Score
This way, in a 7-item, 1-7 coding scheme, 1s become 7s ((7+1)-1 = 7), 2s become 6s ((7+1)-2 = 6) etc.
```{r}
#Attachment Items: 1 - 9
summary(df$Attach_1) #properly on 1-7 scale

##Attachment Avoidance
#Attachment items with reversed coding (r): 1R, 2R, 3R, 4R, 5, 6
df$Attach_1R <- 8 - df$Attach_1
df$Attach_2R <- 8 - df$Attach_2
df$Attach_3R <- 8 - df$Attach_3
df$Attach_4R <- 8 - df$Attach_4
df$Attach_avd <- rowMeans(df[, c("Attach_1R", "Attach_2R", "Attach_3R", "Attach_4R", "Attach_5", "Attach_6")], na.rm = T)

##Attachment Anxiety
#Attachment items (no reverse coding): 7,8,9
df$Attach_anx <- rowMeans(df[, c("Attach_7", "Attach_8", "Attach_9")], na.rm = T)
```
Kama Muta (KM)
KM is made up of 5 aspects, all measured separately: Physical reaction (KM_P), Communal sharing relationship appraisal (KM_CSR), prosocial Motivation (KM_M), positive affect, and lexical label (KM_L). We remove positive affect here for the sake of separately measuring it more robustly via the PANAS.

```{r}
#KM_P (Physiology) Items: KM_P_1-12
df$KM_P <- rowMeans(df[, c("KM_P_1","KM_P_2", "KM_P_3", "KM_P_4" ,"KM_P_5", "KM_P_6", "KM_P_7", "KM_P_8", "KM_P_9", "KM_P_10", "KM_P_11","KM_P_12")], na.rm = T)

#KM_CSR (Communal Sharing Relationship appraisal) Items: KM_CSR_1-4
df$KM_CSR <- rowMeans(df[, c("KM_CSR_1","KM_CSR_2","KM_CSR_3", "KM_CSR_4")], na.rm = T)

#KM_M (prosocial Motive): KM_M_1-4
df$KM_M <- rowMeans(df[, c("KM_M_1","KM_M_2", "KM_M_3", "KM_M_4")], na.rm = T)

#KM_L (Lexical Label): KM_L_1-3
df$KM_L <- rowMeans(df[, c("KM_L_1", "KM_L_2", "KM_L_3")], na.rm = T)
```

The KAMMUS Scale technically only reflects the likelihood of a given experience being kama muta, rather than a direct measure of the emotion itself. As such, a complete KM score cannot be summed together. We instead directly apply a probability function to the kama muta scores to quantitatively reflect this scale issue.

KM_Avg
First we compile a single KM average. Note the scale metric of the KAMMUS is 0-6. 3 is the midpoint, whereby scores above 3 are middling indicator of the experience being KM, while scores of 0 ("Not at All") and 6 ("A Lot") reflect very low and very high likelihood of the experience being KM. Therefore, an average score across all subscales will reflect similarly (e.g. the equivalent of marking 0 on every subscale item, will have an average of 0, marking very low likelihood. Marking a 6 on every subscale item will have an average of 7, marking very high likelihood.)

KM_Scl
We apply a sigmoid function to create reflect a non-linear scaling of these scores to reflect "probablity" (which is typically expressed via a sigmoid function a la logistical regressions). Note, the sigmoid function f(x) = 1/(1+e^-x) means that f(0) = 0.5 or 50% probablity. The goal is therefore to have 3, the middle of the KAMMUS scale, to reflect this 50% probability--such that scores above 3 mark higher likelihoods, lower scores mark lower likelihoods. I.e. we center scale the KAMMUS scores to 3

pKM
"Probability of KM", or p(KM), is the final implementation of the sigmoid function on this centered KM variable. **Note, this study's initial focus is on disentangling PA's influence, so remember that KM effects with this construction are sans PA**

```{r}
df$KM_Avg <- (df$KM_P + df$KM_CSR + df$KM_M + df$KM_L)/4

df$KM_Scl <- df$KM_Avg - 3

df$pKM <- 1/(1+(exp(1)^-(df$KM_Scl)))
```

You can see this non-linear pathway by comparing the KM average scores to this new pKM "probability" variable
```{r}
library(ggplot2)
ggplot(df, aes(x = KM_Scl, y = pKM)) +
  geom_point() #Average KM scores of 3 middle of the scale, now zeroed, are considered 50% likely to have experienced KM.
```


PANAS: Positive and Negative Affect
```{r}
##Negative Affect
#Negative items (no reverse coding): PANAS_NA1-5
df$NegAff <- rowMeans(df[,c("PANAS_NA1", "PANAS_NA2", "PANAS_NA3", "PANAS_NA4", "PANAS_NA5")], na.rm = T) 

##Positive Affect
#Positive items (no reverse coding): PANAS_PA1-5
df$PosAff <- rowMeans(df[,c("PANAS_PA1", "PANAS_PA2", "PANAS_PA3", "PANAS_PA4", "PANAS_PA5")], na.rm = T) 

```

T2 Autonomy Satisfaction & Frustration
```{r}
#Aut Sat items: 1, 2, 3, 4
df$ANS_2 <- rowMeans(df[,c("Aut2S_1", "Aut2S_2", "Aut2S_3", "Aut2S_4")], na.rm = T)

#Aut Frus items: 5, 6, 7, 8
df$ANF_2 <- rowMeans(df[,c("Aut2F_5", "Aut2F_6", "Aut2F_7", "Aut2F_8")], na.rm = T)
```

T2 Relatedness Satisfaction & Frustration
```{r}
#Rel Sat items: 1, 2, 3, 4
df$RNS_2 <- rowMeans(df[,c("Rel2S_1", "Rel2S_2", "Rel2S_3", "Rel2S_4")], na.rm = T)

#Rel Frus itmes: 5, 6, 7, 8
df$RNF_2 <- rowMeans(df[,c("Rel2F_5", "Rel2F_6", "Rel2F_7", "Rel2F_8")], na.rm = T)
```

T2 Competency Satisfaction & Frustration
```{r}
#Comp Sat items: 1, 2, 3, 4
df$CNS_2 <- rowMeans(df[,c("Comp2S_1", "Comp2S_2", "Comp2S_3", "Comp2S_4")], na.rm = T)

#Comp Frus itmes: 5, 6, 7, 8
df$CNF_2 <- rowMeans(df[,c("Comp2F_5", "Comp2F_6", "Comp2F_7", "Comp2F_8")], na.rm = T)
```


### Checking for Data Issues, Removing Problem Cases
The data processing is nearly done,now to check and attend to some final quality signs

To start, we had an Attention Check (AttCheck_1) earlier, but we also had a 2nd attention check--whether participants correctly self-reported the video they watched. Let's cross-reference that with the actual video they were shown. People who correctly reported their video pass, those who incorrectly report fail this 2nd attention check

```{r}
table(df$Vid_SelfRep, df$Cond)
```
Luckily it appears the incorrect answers (8 of them) are spread across all three conditions, suggesting the incorrect answers are not due to a condition's video being particularly difficult/vague to identify when asked directly. We can label these for the 2nd attention check

```{r}
df$AttCheck_2 <- ifelse(as.character(df$Vid_SelfRep) == as.character(df$Cond),
                        "Pass",
                        "Fail")
table(ifelse(as.character(df$Vid_SelfRep) == as.character(df$Cond),
                        "Pass",
                        "Fail")) #checking the new variable is tracking correctly to our previous table
```
### Evaluating Problems for Removal
How many people had issues with the audio?
```{r}
table(df$Vid_Audio)
```
Appears we have 9 people who didn't hear the audio.

Video Issues
```{r}
table(df$Vid_Issue)
unique(df$Vid_Issue_Text)
```
Had 7 people who had some video issue.

##### Timing
Participants who completed the entire survey in less than five minutes will not be kept (considering the videos alone are all roughly 2.5 minutes)
```{r}
summary(df$Survey_Duration)

subset(df, Survey_Duration <= 300) #300 seconds referring to 5minutes (60*5)
```


Time on Video Page
Each of the video page's had a timer. We can check now if people stayed on the page for the entire duration of the video.
Neutral duration: 201 seconds
KM duration: 176 seconds
Amuse duration: 146 seconds
```{r}
subset(df, Neutral_Timer < 201)
```
```{r}
subset(df, KM_Timer < 176)
```

```{r}
subset(df, Amuse_Timer < 146)
```
Some of these participants have timers very close to the actual video length, e.g. within 5 seconds. However, we cannot confirm whether participants immediately started the video upon entering, therefore even a timer showing 5 seconds less than the video length does not necessarily mean the participant watch all but 5 seconds of the video (i.e.the timer is more likely an overestimate, than underestimate, of the amount of the video they watched)

### Removal Criteria
Now to remove cases. We'll create a new "missing" variable to log the reasons for each cut

```{r}
df$missing <- NA
#Consent
df$missing[df$Consent != "Consent" | is.na(df$Consent)] <- "No Consent Confirmation"

#Duration
df$missing[df$Survey_Duration <=300] <- "Sub-5 Min Completion"

#Timers
df$missing[df$Neutral_Timer < 201] <- "Quick Neutral Video"
df$missing[df$KM_Timer < 176] <- "Quick KM Video"
df$missing[df$Amuse_Timer < 146] <- "Quick Amuse Video"

#Attention Checks
df$missing[df$AttCheck_2 == "Fail" | is.na(df$AttCheck_2)] <- "Failed 2nd Attention Check"
df$missing[df$AttCheck_1 == "Fail" | is.na(df$AttCheck_1)] <- "Failed 1st Attention Check"

#Technical Issues
df$missing[df$Vid_Audio == "No"] <- "No Video Audio"
df$missing[df$Vid_Issue == "Yes"] <- "Video Issue"
```

```{r}
missing_table <- table(df$missing)
missing_table
```
Now we can remove those people from the dataset
```{r}
df <- 
  df %>% filter(is.na(missing))
```

#### Standardizing Relevant Variables

Now to make some standardized versions of some variables we'll use in analysis later on 

```{r}
df$ANS_1_Z <- scale(df$ANS_1)[,1] #weird new formatting where scale(var) creates a matrix. But we only want the numbers, not creating a mini array for the column
df$ANF_1_Z <- scale(df$ANF_1)[,1]
df$RNS_1_Z <- scale(df$RNS_1)[,1]
df$RNF_1_Z <- scale(df$RNF_1)[,1]
df$CNS_1_Z <- scale(df$CNS_1)[,1]
df$CNF_1_Z <- scale(df$CNF_1)[,1]
df$pKM_Z <- scale(df$pKM)[,1]
df$NegAff_Z <- scale(df$NegAff)[,1]
df$PosAff_Z <- scale(df$PosAff)[,1]
df$ANS_2_Z <- scale(df$ANS_2)[,1]
df$ANF_2_Z <- scale(df$ANF_2)[,1]
df$RNS_2_Z <- scale(df$RNS_2)[,1]
df$RNF_2_Z <- scale(df$RNF_2)[,1]
df$CNS_2_Z <- scale(df$CNS_2)[,1]
df$CNF_2_Z <- scale(df$CNF_2)[,1]
```

#### Final df Check
```{r}
summary(df)
```
Good, not seeing any unspoken for NAs

## Initial Visualizations
```{r eval=FALSE}
library(ggplot2)
library(viridis)
library(gridExtra)
```


```{r}
nrow(df) # = 352
#Age
p1 <- ggplot(df, aes(x = Age)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Age Distribution (n=352)",
       x = "Age (Binwidth = 1)",
       y = "Count")
#Race
p2 <- ggplot(df, aes(x = Race)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  labs(title = "Ethnicity/Race Distribution (n=352)",
       y = "Count")

grid.arrange(p1,p2, nrow = 1)
```
```{r}
#Education
p1 <- ggplot(df, aes(x = Education)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 10, vjust = 0.5))+
  labs(title = "Education Distribution (n=352)",
       x = "Education",
       y = "Count")
#Income
p2 <- ggplot(df, aes(x = Income)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 10, vjust = 0.5))+
  labs(title = "Income Distribution (n=352)",
       x = "Income",
       y = "Count")

grid.arrange(p1,p2, nrow = 2)
```

### Checking Condition Success, KM and Positive Affect

Main KM variable of interest
```{r}
ggplot(df, aes(Cond, pKM, fill = Cond)) +
  geom_violin() +
  geom_boxplot(width = 0.1, color = "black", alpha = 0.4) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(title = "Violin Distribution of Kama Muta Experience",
       x = "",
       y = "pKM")
```
```{r}
ggplot(df, aes(Cond, PosAff_Z, fill = Cond)) +
  geom_violin() +
  geom_boxplot(width = 0.1, color = "black", alpha = 0.4) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(title = "Violin Distribution of Positive Affect",
       x = "",
       y = "Positive Affect (Standardized)")
ggsave("PA_Group.png")
```


```{r}
ggplot(df, aes(x = KM_Avg, y = pKM, color = Cond)) +
  geom_jitter(height = .05) +
  labs(x = "Average Response on KAMMUS Two",
       y = "Probability of Kama Muta Experience",
       color = "Condition")
```

Individual KM Aspects
```{r}
p1 <- ggplot(df, aes(KM_P, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "Physiological Signs",
       y = "Density")

p2 <- ggplot(df, aes(KM_CSR, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "CSR Appraisal",
       y = "Density")

p3 <- ggplot(df, aes(KM_M, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "Prosocial Motivation",
       y = "Density")

p4 <- ggplot(df, aes(KM_L, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "Lexical Label",
       y = "Density")

grid.arrange(p1,p2,p3,p4, nrow = 2)
```

Positive affect
```{r}
ggplot(df, aes(PosAff, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "Positive Affect",
       y = "Density")
```

```{r}
p1 <- ggplot(df, aes(Cond, ANS_1, fill = Cond)) +
  geom_violin() +
  geom_boxplot(width = 0.1, color = "black", alpha = 0.4) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(title = "Time 1 Autonomy Satisfaction",
       x = "",
       y = "")

p2 <- ggplot(df, aes(Cond, ANF_1, fill = Cond)) +
  geom_violin() +
  geom_boxplot(width = 0.1, color = "black", alpha = 0.4) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(title = "Time 1 Autonomy Frustration",
       x = "",
       y = "")
p3 <- ggplot(df, aes(Cond, RNS_1, fill = Cond)) +
  geom_violin() +
  geom_boxplot(width = 0.1, color = "black", alpha = 0.4) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(title = "Time 1 Relatedness Satisfaction",
       x = "",
       y = "")

p4 <- ggplot(df, aes(Cond, RNF_1, fill = Cond)) +
  geom_violin() +
  geom_boxplot(width = 0.1, color = "black", alpha = 0.4) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(title = "Time 1 Relatedness Frustration",
       x = "",
       y = "")
p5 <- ggplot(df, aes(Cond, CNS_1, fill = Cond)) +
  geom_violin() +
  geom_boxplot(width = 0.1, color = "black", alpha = 0.4) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(title = "Time 1 Competence Satisfaction",
       x = "",
       y = "")
p6 <- ggplot(df, aes(Cond, CNF_1, fill = Cond)) +
  geom_violin() +
  geom_boxplot(width = 0.1, color = "black", alpha = 0.4) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(title = "Time 1 Competence Frustration",
       x = "",
       y = "")

grid.arrange(p1,p2,p3,p4,p5,p6, nrow = 3)
ggsave("Time 1 By Condition.png")
```


```{r}
p1 <- ggplot(df, aes(ANS_1, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "ANS Time 1",
       y = "Density")

p2 <- ggplot(df, aes(ANS_2, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "ANS Time 2",
       y = "Density")

grid.arrange(p1,p2, nrow = 2)
```

```{r}
p1 <- ggplot(df, aes(RNS_1, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "RNS Time 1",
       y = "Density")

p2 <- ggplot(df, aes(RNS_2, group = Cond, fill = Cond)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(x = "RNS Time 2",
       y = "Density")

grid.arrange(p1,p2, nrow = 2)
```
Autonomy Needs
```{r}
df_plot <- df %>% 
  select("Cond", "ANS_1", "ANS_2") %>% 
  pivot_longer(cols = c("ANS_1", "ANS_2"),
               names_to = "Time",
               values_to = "Score")

p1 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

df_plot <- df %>% 
  select("Cond", "ANF_1", "ANF_2") %>% 
  pivot_longer(cols = c("ANF_1", "ANF_2"),
               names_to = "Time",
               values_to = "Score")

p2 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

grid.arrange(p1, p2, nrow = 1)
```


Relatedness Needs
```{r}
df_plot <- df %>% 
  select("Cond", "RNS_1", "RNS_2") %>% 
  pivot_longer(cols = c("RNS_1", "RNS_2"),
               names_to = "Time",
               values_to = "Score")

p1 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

df_plot <- df %>% 
  select("Cond", "RNF_1", "RNF_2") %>% 
  pivot_longer(cols = c("RNF_1", "RNF_2"),
               names_to = "Time",
               values_to = "Score")

p2 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

grid.arrange(p1, p2, nrow = 1)
```


```{r}
df %>% 
  group_by(Cond) %>% 
  summarise_at(vars(RNS_2), list(name = mean))

df %>% 
  group_by(Cond) %>% 
  summarise_at(vars(RNS_1), list(name = mean))
```


Competency Needs
```{r}
df_plot <- df %>% 
  select("Cond", "CNS_1", "CNS_2") %>% 
  pivot_longer(cols = c("CNS_1", "CNS_2"),
               names_to = "Time",
               values_to = "Score")

p1 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

df_plot <- df %>% 
  select("Cond", "CNF_1", "CNF_2") %>% 
  pivot_longer(cols = c("CNF_1", "CNF_2"),
               names_to = "Time",
               values_to = "Score")

p2 <- ggplot(df_plot, aes(x = Time, y = Score, fill = Cond)) +
  geom_boxplot() +
  scale_fill_viridis(discrete=TRUE, name = "Condition")+
  labs(y = "Score")

grid.arrange(p1, p2, nrow = 1)

```

## Variable Correlations
We'll load the hmisc function to get correlation matrices with p-values

First, some descriptive variables 
```{r}
library(Hmisc)
df_cor <- df %>%
  select(Age, EC, Attach_avd, Attach_anx, pKM, PosAff)
rcorr(as.matrix(df_cor))
```
More descriptive variables 
```{r}
df_cor <- df %>%
  select(KM_P, KM_CSR, KM_M, PosAff, KM_L, EC, Gender, Age)
df_cor$Gender <- as.numeric(df_cor$Gender)-1 #just to keep as 0,1 coding rather than 1,2
rcorr(as.matrix(df_cor))
```

Now to outcome variables
KM
```{r}
df_cor <- df %>%
  select(pKM, KM_P, KM_CSR, KM_L, KM_M)
rcorr(as.matrix(df_cor))
```
```{r}
df_cor <- df %>%
  select(ANF_1, ANF_2, KM_M)
rcorr(as.matrix(df_cor))
```

ARC Needs
```{r}
df_cor <- df %>%
  select(ANS_1, ANF_1, RNS_1, RNF_1, CNS_1, CNF_1,
         ANS_2, ANF_2, RNS_2, RNF_2, CNS_2, CNF_2,
         pKM, PosAff)
rcorr(as.matrix(df_cor))
```

(I think it's actually that KM "does what it does" by accessing and directing PA. By itself the KM variable isn't much, but it seems to really tap the PA side, even more than the amusement. I.e. PA should turn up across the board, no matter the source--if anything, KM cond might still get the bump because it's better at PA than the other stuff)


An optional, Bayesian framing of the correlation table

```{r}
library(correlation)
library(BayesFactor)

correlation(df[, 
               c('KM_P', 'KM_CSR', 'KM_M', 'KM_L', 'PosAff', 'EC', 'Age')],
            bayesian = T) #can't add gender in here since ordinal var
```

```{r}
library(correlation)
library(BayesFactor)
correlation(df[, 
               c('Age', 'EC', 'Attach_avd', 'Attach_anx',
                 'ANS_1', 'ANF_1', 'RNS_1', 'RNS_1', 'CNS_1','CNF_1',
                 'ANS_2', 'ANF_2', 'RNS_2', 'RNS_2', 'CNS_2','CNF_2',
                 'pKM','PosAff')],
            bayesian = T)
```


## Bayesian Estimation Models


Trying again, but with BSEM so that we can specify the exact indirect effects we want. Note: (B)Lavaan needs the exogenous categorical variables as dummy vars--it won't automatically apply dummy coding like lm() functions do

```{r}
#model.matrix(~df$Cond + 0)
#model.matrix(~df$Cond + 0)[,2:3]
#model.matrix(~df$Cond + 0)[,2] #Amuse
#model.matrix(~df$Cond + 0)[,3] #KM

df$CondAmuse <-  model.matrix(~df$Cond + 0)[,2]
df$CondKM <- model.matrix(~df$Cond + 0)[,3]

#we could specify the CondCont, but that is the intercept when using dummy coding, which is specified in the intercept section of the model (see below), so no need for that here
```


Just to make sure there isn't anything crazy going on, I made these models piecemeal, one need group at a time. This way I can compare to my original lm() based models to see if I have any major discrepancy issues (which would signal to me a likely coding error/mistake). Also, this can help me learn how these individual models compare to the overall giant model when all put together! (Turns out, exactly as they should! They all line up, where the smaller model estimates and HDIs line up almost exactly with the full model, difference is so small to be likely random draw/iteration based and not real)
```{r}
library(blavaan)
library(brms)
library(qgraph)
library(bayestestR)
options(mc.cores = parallel::detectCores())

A.model <- '
#Regressions: Mediators, PA & KM. Priors of parameters + parameters
pKM_Z ~ prior("normal(0,2)")*CondAmuse + prior("normal(1.4,.10)")*CondKM + 
 aKM2*CondAmuse+ aKM1*CondKM
PosAff_Z ~ prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM +
aPA2*CondAmuse + aPA1*CondKM 

#Regressions: Outcomes, ARC Sat/Frus. Priors of parameters + parameters
ANS_2_Z ~ prior("normal(0,2)")*pKM_Z + prior("normal(0.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM + prior("normal(0,2)")*ANS_1_Z +
bASi*pKM_Z + bASii*PosAff_Z + cAS1*CondKM + cAS2*CondAmuse +dAS*ANS_1_Z

ANF_2_Z ~ prior("normal(0,2)")*pKM_Z + prior("normal(-0.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM + prior("normal(0,2)")*ANF_1_Z +
bAFi*pKM_Z + bAFii*PosAff_Z + aAF1*CondKM + cAF2*CondAmuse + dAF*ANF_1_Z

#Intercepts: 
pKM_Z~ prior("normal(-2.1,.12)")*1 +
intKM*1
PosAff_Z ~ prior("normal(0,2)")*1 +
intPA*1
ANS_2_Z ~ prior("normal(0,2)")*1 +
intAS*1
ANF_2_Z ~ prior("normal(0,2)")*1 +
intAF*1

#Outcome Estimators:
IAS_KM_KM:= aKM1*bASi
IAS_KM_Amuse:= aKM2*bASi
IAS_KM_Con:= intKM*bASi
IAS_PA_KM:= aPA1*bASii
IAS_PA_Amuse:= aPA2*bASii
IAS_PA_Con:= intPA*bASii
IAF_KM_KM:= aKM1*bAFi
IAF_KM_Amuse:= aKM2*bAFi
IAF_KM_Con:= intKM*bAFi
IAF_PA_KM:= aPA1*bAFii
IAF_PA_Amuse:= aPA2*bAFii
IAF_PA_Con:= intPA*bAFii
'
```

```{r}
fit_A <- bsem(A.model, data = df, n.chains = 4, burnin = 1000, sample = 5000, seed = 123) #5000, 10000 for full (takes ~1.5hrs)
```
```{r}
summary(fit_A)
```

```{r}
library(blavaan)
library(brms)
library(qgraph)
library(bayestestR)
options(mc.cores = parallel::detectCores())

R.model <- '
#Regressions: Mediators, PA & KM. Priors of parameters + parameters
pKM_Z ~ prior("normal(0,2)")*CondAmuse + prior("normal(1.4,.10)")*CondKM + 
 aKM2*CondAmuse+ aKM1*CondKM
PosAff_Z ~ prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM +
aPA2*CondAmuse + aPA1*CondKM 

#Regressions: Outcomes, ARC Sat/Frus. Priors of parameters + parameters
RNS_2_Z ~ prior("normal(0.09,.03)")*pKM_Z + prior("normal(.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(0.11,.05)")*CondKM + prior("normal(.75,.02)")*RNS_1_Z +
bRSi*pKM_Z + bRSii*PosAff_Z + cRS1*CondKM + cRS2*CondAmuse + dRS*RNS_1_Z

RNF_2_Z ~ prior("normal(-.05,.02)")*pKM_Z + prior("normal(-.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(-.05,.04)")*CondKM + prior("normal(0.87,.02)")*RNF_1_Z +
bRFi*pKM_Z + bRFii*PosAff_Z + cRF1*CondKM + cRF2*CondAmuse + dRF*RNF_1_Z


#Intercepts: 
pKM_Z~ prior("normal(-2.1,.12)")*1 +
intKM*1
PosAff_Z ~ prior("normal(0,2)")*1 +
intPA*1
RNS_2_Z ~ prior("normal(-.16,.08)")*1 +
intRS*1
RNF_2_Z ~ prior("normal(.08,.06)")*1 +
intRF*1


#Outcome Estimators:
IRS_KM_KM:= aKM1*bRSi
IRS_KM_Amuse:= aKM2*bRSi
IRS_KM_Con:= intKM*bRSi
IRS_PA_KM:= aPA1*bRSii
IRS_PA_Amuse:= aPA2*bRSii
IRS_PA_Con:= intPA*bRSii
IRF_KM_KM:= aKM1*bRFi
IRF_KM_Amuse:= aKM2*bRFi
IRF_KM_Con:= intKM*bRFi
IRF_PA_KM:= aPA1*bRFii
IRF_PA_Amuse:= aPA2*bRFii
IRF_PA_Con:= intPA*bRFii
'
```

```{r}
fit_R <- bsem(R.model, data = df, n.chains = 4, burnin = 1000, sample = 5000, seed = 123) #5000, 10000 for full (takes ~1.5hrs)
```
```{r}
summary(fit_R)
```
```{r}
library(blavaan)
library(brms)
library(qgraph)
library(bayestestR)
options(mc.cores = parallel::detectCores())

C.model <- '
#Regressions: Mediators, PA & KM. Priors of parameters + parameters
pKM_Z ~ prior("normal(0,2)")*CondAmuse + prior("normal(1.4,.10)")*CondKM + 
 aKM2*CondAmuse+ aKM1*CondKM
PosAff_Z ~ prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM +
aPA2*CondAmuse + aPA1*CondKM 

#Regressions: Outcomes, ARC Sat/Frus. Priors of parameters + parameters
CNS_2_Z ~ prior("normal(0,2)")*pKM_Z + prior("normal(0.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM + prior("normal(0,2)")*CNS_1_Z +
bCSi*pKM_Z + bCSii*PosAff_Z + cCS1*CondKM + cCS2*CondAmuse + dCS*CNS_1_Z

CNF_2_Z ~ prior("normal(0,2)")*pKM_Z + prior("normal(-0.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM + prior("normal(0,2)")*CNF_1_Z +
bCFi*pKM_Z + bCFii*PosAff_Z + cCF1*CondKM + cCF2*CondAmuse + dCF*CNF_1_Z

#Intercepts: 
pKM_Z~ prior("normal(-2.1,.12)")*1 +
intKM*1
PosAff_Z ~ prior("normal(0,2)")*1 +
intPA*1
CNS_2_Z ~ prior("normal(0,2)")*1 +
intCS*1
CNF_2_Z ~ prior("normal(0,2)")*1 +
intCF*1

#Outcome Estimators:
ICS_KM_KM:= aKM1*bCSi
ICS_KM_Amuse:= aKM2*bCSi
ICS_KM_Con:= intKM*bCSi
ICS_PA_KM:= aPA1*bCSii
ICS_PA_Amuse:= aPA2*bCSii
ICS_PA_Con:= intPA*bCSii
ICF_KM_KM:= aKM1*bCFi
ICF_KM_Amuse:= aKM2*bCFi
ICF_KM_Con:= intKM*bCFi
ICF_PA_KM:= aPA1*bCFii
ICF_PA_Amuse:= aPA2*bCFii
ICF_PA_Con:= intPA*bCFii
'
```

```{r}
fit_C <- bsem(C.model, data = df, n.chains = 4, burnin = 1000, sample = 5000, seed = 123) #5000, 10000 for full (takes ~1.5hrs)
```

```{r}
summary(fit_C)
```


```{r}
library(blavaan)
library(brms)
library(qgraph)
library(bayestestR)
options(mc.cores = parallel::detectCores())

ARC.model <- '
#Regressions: Mediators, PA & KM. Priors of parameters + parameters
pKM_Z ~ prior("normal(0,2)")*CondAmuse + prior("normal(1.4,.10)")*CondKM + 
 aKM2*CondAmuse+ aKM1*CondKM
PosAff_Z ~ prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM +
aPA2*CondAmuse + aPA1*CondKM 

#Regressions: Outcomes, ARC Sat/Frus. Priors of parameters + parameters
ANS_2_Z ~ prior("normal(0,2)")*pKM_Z + prior("normal(0.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM + prior("normal(0,2)")*ANS_1_Z +
bASi*pKM_Z + bASii*PosAff_Z + cAS1*CondKM + cAS2*CondAmuse +dAS*ANS_1_Z

ANF_2_Z ~ prior("normal(0,2)")*pKM_Z + prior("normal(-0.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM + prior("normal(0,2)")*ANF_1_Z +
bAFi*pKM_Z + bAFii*PosAff_Z + aAF1*CondKM + cAF2*CondAmuse + dAF*ANF_1_Z

RNS_2_Z ~ prior("normal(0.09,.03)")*pKM_Z + prior("normal(.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(0.11,.05)")*CondKM + prior("normal(.75,.02)")*RNS_1_Z +
bRSi*pKM_Z + bRSii*PosAff_Z + cRS1*CondKM + cRS2*CondAmuse + dRS*RNS_1_Z

RNF_2_Z ~ prior("normal(-.05,.02)")*pKM_Z + prior("normal(-.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(-.05,.04)")*CondKM + prior("normal(0.87,.02)")*RNF_1_Z +
bRFi*pKM_Z + bRFii*PosAff_Z + cRF1*CondKM + cRF2*CondAmuse + dRF*RNF_1_Z

CNS_2_Z ~ prior("normal(0,2)")*pKM_Z + prior("normal(0.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM + prior("normal(0,2)")*CNS_1_Z +
bCSi*pKM_Z + bCSii*PosAff_Z + cCS1*CondKM + cCS2*CondAmuse + dCS*CNS_1_Z

CNF_2_Z ~ prior("normal(0,2)")*pKM_Z + prior("normal(-0.1,1)")*PosAff_Z + prior("normal(0,2)")*CondAmuse + prior("normal(0,2)")*CondKM + prior("normal(0,2)")*CNF_1_Z +
bCFi*pKM_Z + bCFii*PosAff_Z + cCF1*CondKM + cCF2*CondAmuse + dCF*CNF_1_Z

#Intercepts: 
pKM_Z~ prior("normal(-2.1,.12)")*1 +
intKM*1
PosAff_Z ~ prior("normal(0,2)")*1 +
intPA*1
ANS_2_Z ~ prior("normal(0,2)")*1 +
intAS*1
ANF_2_Z ~ prior("normal(0,2)")*1 +
intAF*1
RNS_2_Z ~ prior("normal(-.16,.08)")*1 +
intRS*1
RNF_2_Z ~ prior("normal(.08,.06)")*1 +
intRF*1
CNS_2_Z ~ prior("normal(0,2)")*1 +
intCS*1
CNF_2_Z ~ prior("normal(0,2)")*1 +
intCF*1

#Outcome Estimators:
IAS_KM_KM:= aKM1*bASi
IAS_KM_Amuse:= aKM2*bASi
IAS_KM_Con:= intKM*bASi
IAS_PA_KM:= aPA1*bASii
IAS_PA_Amuse:= aPA2*bASii
IAS_PA_Con:= intPA*bASii
IAF_KM_KM:= aKM1*bAFi
IAF_KM_Amuse:= aKM2*bAFi
IAF_KM_Con:= intKM*bAFi
IAF_PA_KM:= aPA1*bAFii
IAF_PA_Amuse:= aPA2*bAFii
IAF_PA_Con:= intPA*bAFii

IRS_KM_KM:= aKM1*bRSi
IRS_KM_Amuse:= aKM2*bRSi
IRS_KM_Con:= intKM*bRSi
IRS_PA_KM:= aPA1*bRSii
IRS_PA_Amuse:= aPA2*bRSii
IRS_PA_Con:= intPA*bRSii
IRF_KM_KM:= aKM1*bRFi
IRF_KM_Amuse:= aKM2*bRFi
IRF_KM_Con:= intKM*bRFi
IRF_PA_KM:= aPA1*bRFii
IRF_PA_Amuse:= aPA2*bRFii
IRF_PA_Con:= intPA*bRFii

ICS_KM_KM:= aKM1*bCSi
ICS_KM_Amuse:= aKM2*bCSi
ICS_KM_Con:= intKM*bCSi
ICS_PA_KM:= aPA1*bCSii
ICS_PA_Amuse:= aPA2*bCSii
ICS_PA_Con:= intPA*bCSii
ICF_KM_KM:= aKM1*bCFi
ICF_KM_Amuse:= aKM2*bCFi
ICF_KM_Con:= intKM*bCFi
ICF_PA_KM:= aPA1*bCFii
ICF_PA_Amuse:= aPA2*bCFii
ICF_PA_Con:= intPA*bCFii
'
```

```{r}
fit_ARC <- bsem(ARC.model, data = df, n.chains = 4, burnin = 5000, sample = 10000, seed = 123)
#note the https://arxiv.org/abs/2301.08667 link about priors--I preregistered these priors, so we'll stick with em', but some priors might have changed behind the scenes, specifically that psi prior--which should be fine, since it's the latent var precision parameter (and we have no latent vars here)
```


```{r}
summary(fit_ARC)
```

```{r}
library(bayesplot)
library(ggplot2)
color_scheme_set("viridis")

#Chain Mixing Plots
plot(fit_ARC, pars = c(1:4, 35, 36), plot.type = "trace")#M Side
ggsave("M_Trace_Plots.png")
plot(fit_ARC, pars = c(5:14, 37,38), plot.type = "trace")#A Side
ggsave("A_Trace_Plots.png")
plot(fit_ARC, pars = c(15:24, 39,40), plot.type = "trace")#R Side
ggsave("R_Trace_Plots.png")
plot(fit_ARC, pars = c(25:34, 41,42), plot.type = "trace")#C Side
ggsave("C_Trace_Plots.png")
```

```{r}
#Autocorrelation Mixing Plots
plot(fit_ARC, pars = c(1:4, 35, 36), plot.type = "acf")#M Side
ggsave("M_Autorcor_Plots.png")
plot(fit_ARC, pars = c(5:14, 37,38), plot.type = "acf")#A Side
ggsave("A_Autorcor_Plots.png")
plot(fit_ARC, pars = c(15:24, 39,40), plot.type = "acf")#R Side
ggsave("R_Autorcor_Plots.png")
plot(fit_ARC, pars = c(25:34, 41,42), plot.type = "acf")#C Side
ggsave("C_Autorcor_Plots.png")
```


Effective Sample Size
```{r}
blavInspect(fit_ARC, "neff")
```

## Old Regressions (Deprecated, but keeping for reference)

### X->M Pathway

The mediation is a X->M->Y pathway.
Let's focus on the first leg: X -> M. I.e. do the conditions themselves predict pKM and PosAff (our two mediators)

#### Fitting our model
Let's check the names of the priors in the model so that we can properly specify them when running the actual model.
```{r}
get_prior(mvbind(pKM_Z, PosAff_Z) ~ Cond,
    data = df)
```

Using 20k iterations--ESS ideally is 10k+ (Kruschke, 2021), so we likely need more than 10k iterations to get an ESS of 10K 
```{r}
fit_M <- brm(mvbind(pKM_Z, PosAff_Z) ~ Cond,
    df,
    prior = c(
      set_prior("normal(-2.1,.12)", class = "Intercept", resp = "pKMZ"),
      set_prior("normal(1.4,.10)", class = "b", coef = "CondKM", resp = "pKMZ"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse", resp = "pKMZ"),
      set_prior("normal(0,2)", class = "Intercept", resp = "PosAffZ"),
      set_prior("normal(0,2)", class = "b", coef = "CondKM", resp = "PosAffZ"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse", resp = "PosAffZ")
    ),
    warmup = 5000, iter = 20000, chains = 4)
```



#### Plotting model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_M)
dimnames(posterior)

color_scheme_set("viridis")

```

##### Chain Mixing Plots
```{r}
mcmc_trace(posterior, pars = c("b_pKMZ_Intercept","b_PosAffZ_Intercept",
                               "b_pKMZ_CondAmuse","b_pKMZ_CondKM",
                               "b_PosAffZ_CondAmuse","b_PosAffZ_CondKM",
                               "sigma_pKMZ","sigma_PosAffZ"),
           facet_args = list(ncol = 2))
ggsave("M_Trace_Plots.png")
```


##### Autocorrelation Plots
```{r}
mcmc_acf(posterior,pars = c("b_pKMZ_Intercept","b_PosAffZ_Intercept",
                               "b_pKMZ_CondAmuse","b_pKMZ_CondKM",
                               "b_PosAffZ_CondAmuse","b_PosAffZ_CondKM",
                               "sigma_pKMZ","sigma_PosAffZ"))
ggsave("M_Autorcor_Plots.png")
```

```{r}
mcmc_acf(posterior,pars = c("b_pKMZ_CondAmuse","b_pKMZ_CondKM", "b_PosAffZ_CondAmuse", "b_PosAffZ_CondKM"))
```


#### Summaries of the Model
```{r}
summary(fit_M)
print(summary(fit_M), digits = 3) #to see more decimal places,particularly helpful for the Rhat stats
```
Remember, all of these effects are the **medians** of their respective distributions.

Another, perhaps easier to see though less detailed summary
```{r}
describe_posterior(fit_M)
```

From Vehtari, Gelman, Simpson, Carpenter, Burkner (2019), we know that convergence of the MCs is not necessarily the same across the entire parameter space. Our chain plots show convergence visually, but we can also evaluate convergence in terms of how much stable sampling we were able to achieve in both the "main" part of the distribution and at the outer (typically less stable) ends.
"Bulk_ESS" is the term Bayesians have previously called "Effective Sample Size." It means the number of effective, i.e. independent, samples in the center of the poterior distribution (i.e. make up the "bulk" of the posterior). "Tail_ESS" is consequently about the tails of that distribution (5%-95% quantiles), allowing us to see how many effective samples are in the outer sides of the distribution. Put together, we can get a clearer picture of parameter stability across the distribution. 

Just to show that mvind is basically just smashing two models at once, then doing a correlation between the dvs. In this sense, it's not reaaally multivariate in that it's just doing two at once, but doesn't really change the actual estimation method itself (true multivariate)
```{r}
get_prior(pKM_Z ~ Cond,
    data = df)

fit_m1 <- brm(pKM_Z ~ Cond,
    df,
    prior = c(
      set_prior("normal(-2.1,.12)", class = "Intercept"),
      set_prior("normal(1.4,.10)", class = "b", coef = "CondKM"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse")
    ),
    warmup = 5000, iter = 20000, chains = 4)
  
fit_m2 <- brm(PosAff_Z ~ Cond,
    df,
    prior = c(
      set_prior("normal(0,2)", class = "Intercept"),
      set_prior("normal(0,2)", class = "b", coef = "CondKM"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse")
    ),
    warmup = 5000, iter = 20000, chains = 4)
```


#### Plotting Model Posteriors
```{r}
mcmc_areas(
  posterior,
  pars = c("b_pKMZ_Intercept", "b_PosAffZ_Intercept",
           "b_pKMZ_CondAmuse", "b_pKMZ_CondKM", "b_PosAffZ_CondAmuse","b_PosAffZ_CondKM",
           "sigma_pKMZ", "sigma_PosAffZ"),
  prob = 0.95,
  prob_outer = 0.99,
  point_est = "median"
)
```

```{r}
mcmc_intervals(
  posterior,
  pars = c("b_pKMZ_Intercept", "b_PosAffZ_Intercept",
           "b_pKMZ_CondAmuse", "b_pKMZ_CondKM", "b_PosAffZ_CondAmuse","b_PosAffZ_CondKM",
           "sigma_pKMZ", "sigma_PosAffZ"),
  prob = 0.95,
  prob_outer = 0.99,
  point_est = "mean"
)
```

Marginal (All Chains) Posterior Distributions
```{r}
mcmc_dens(
  posterior,
  pars = c("b_pKMZ_CondAmuse", "b_pKMZ_CondKM", "b_PosAffZ_CondAmuse","b_PosAffZ_CondKM")
)
```

Trying to see direct ROPE numbers
```{r}
describe_posterior(fit_M) #note, multivariate is not supported yet with the ROPE function in BayestestR
```

Looks like we won't be able to see direct ROPE metrics using these multivariate models yet. Can still evaluate the main benchmark (does the CI cross +/- .05 or not) from the posterior estimates and CI, but won't be able to measure specific percentage this way.


### Autonomy Model

####Satisfaction
####Fitting our model
```{r}
get_prior(ANS_2_Z ~ ANS_1_Z + Cond + PosAff_Z + pKM_Z,
          data = df)
```

```{r}
fit_AS <- brm(ANS_2_Z ~ ANS_1_Z + Cond + PosAff_Z + pKM_Z,
    data = df,
    prior = c(
      set_prior("normal(0,2)", class = "b", coef = "pKM_Z"),
      set_prior("normal(.10,1)", class = "b", coef = "PosAff_Z"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse"),
      set_prior("normal(0,2)", class = "b", coef = "CondKM"),
      set_prior("normal(0,2)", class = "b", coef = "ANS_1_Z"),
      set_prior("normal(0,2)", class = "Intercept")
    ),
    warmup = 5000, iter = 20000, chains = 4)

#that "-E" warning is not important--it's a misconfiguration on the developer side (see Stan Forum)
```

#### Plotting our model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_AS)
dimnames(posterior)$variable[1:18]

color_scheme_set("viridis")
```
##### Chain Mixing Plots
```{r}
mcmc_trace(posterior,pars = c("b_Intercept", "b_ANS_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"),
           facet_args = list(ncol = 3))
ggsave("AS_Trace_Plots.png")
```


##### Autocorrelation Plots
```{r}
mcmc_acf(posterior,pars = c("b_Intercept", "b_ANS_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"))
ggsave("AS_Autocor_Plots.png")
```

#### Summaries of the Model
```{r}
summary(fit_AS)
print(summary(fit_AS), digits = 3)
```
Remember, all of these effects are the **medians** of their respective distributions.

Another, perhaps easier to see though less detailed summary
```{r}
describe_posterior(fit_AS)
```
We see that PosAffect has appreciable effects on both ANF and ANS in the directions you'd expect (feel good, feel higher ANS and lower ANS).
We also see that KM does have an effect on ANF--where higher KM **increases** Autonomy frustration-- but does nothing to autonomy satisfaction. We might be seeing a reaction to emotional content--a "don't play with my emotions/being-state" that comes from the videso or perhaps just a nature of the KM emotion itself (perhaps culture dependent? UK/Western cultures I think are less culturally accepting of emotionality--though given this is a generally positive emotion, this culture-specificity might not be sufficient)

#### Frustration
```{r}
get_prior(ANF_2_Z ~ ANF_1_Z + Cond + PosAff_Z + pKM_Z,
    data = df)
```

```{r}
fit_AF <- brm(ANF_2_Z ~ ANF_1_Z + Cond + PosAff_Z + pKM_Z,
    data = df,
    prior = c(
      set_prior("normal(0,2)", class = "b", coef = "pKM_Z"),
      set_prior("normal(-.10,1)", class = "b", coef = "PosAff_Z"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse"),
      set_prior("normal(0,2)", class = "b", coef = "CondKM"),
      set_prior("normal(0,2)", class = "b", coef = "ANF_1_Z"),
      set_prior("normal(0,2)", class = "Intercept")
    ),
    warmup = 5000, iter = 20000, chains = 4)

#that "-E" warning is not important--it's a misconfiguration on the developer side (see Stan Forum)
```

#### Plotting our model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_AF)
dimnames(posterior)$variable[1:18]

color_scheme_set("viridis")
```
##### Chain Mixing Plots
```{r}
mcmc_trace(posterior,pars = c("b_Intercept", "b_ANF_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"),
           facet_args = list(ncol = 3))
ggsave("AF_Trace_Plots.png")
```


##### Autocorrelation Plots
```{r}
mcmc_acf(posterior,pars = c("b_Intercept", "b_ANF_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"))
ggsave("AF_Autocor_Plots.png")
```

#### Summaries of the Model
```{r}
summary(fit_AF)
print(summary(fit_AF), digits = 3)
```
Remember, all of these effects are the **medians** of their respective distributions.

Another, perhaps easier to see though less detailed summary
```{r}
describe_posterior(fit_AF)
```



### Relatedness Model

####Satisfaction
####Fitting our model
```{r}
get_prior(RNS_2_Z ~ RNS_1_Z + Cond + PosAff_Z + pKM_Z,
          data = df)
```

```{r}
fit_RS <- brm(RNS_2_Z ~ RNS_1_Z + Cond + PosAff_Z + pKM_Z,
    data = df,
    prior = c(
      set_prior("normal(0.09,.03)", class = "b", coef = "pKM_Z"),
      set_prior("normal(.10,1)", class = "b", coef = "PosAff_Z"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse"),
      set_prior("normal(0.11,.05)", class = "b", coef = "CondKM"),
      set_prior("normal(0.75,.02)", class = "b", coef = "RNS_1_Z"),
      set_prior("normal(-0.16,.08)", class = "Intercept")
    ),
    warmup = 5000, iter = 20000, chains = 4)

#that "-E" warning is not important--it's a misconfiguration on the developer side (see Stan Forum)
```

#### Plotting our model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_RS)
dimnames(posterior)$variable[1:18]

color_scheme_set("viridis")
```
##### Chain Mixing Plots
```{r}
mcmc_trace(posterior,pars = c("b_Intercept", "b_RNS_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"),
           facet_args = list(ncol = 3))
ggsave("RS_Trace_Plots.png")
```


##### Autocorrelation Plots
```{r}
mcmc_acf(posterior,pars = c("b_Intercept", "b_RNS_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"))
ggsave("RS_Autocor_Plots.png")
```

#### Summaries of the Model
```{r}
summary(fit_RS)
print(summary(fit_RS), digits = 3)
```
Remember, all of these effects are the **medians** of their respective distributions.

Another, perhaps easier to see though less detailed summary
```{r}
describe_posterior(fit_RS)
```



#### Frustration 
#### Fitting our model
```{r}
get_prior(RNF_2_Z ~ RNF_1_Z + Cond + PosAff_Z + pKM_Z,
          data = df)
```

```{r}
fit_RF <- brm(RNF_2_Z ~ RNF_1_Z + Cond + PosAff_Z + pKM_Z,
    data = df,
    prior = c(
      set_prior("normal(-0.05,.02)", class = "b", coef = "pKM_Z"),
      set_prior("normal(-.10,1)", class = "b", coef = "PosAff_Z"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse"),
      set_prior("normal(-0.05,.04)", class = "b", coef = "CondKM"),
      set_prior("normal(0.87,.02)", class = "b", coef = "RNF_1_Z"),
      set_prior("normal(0.08,.06)", class = "Intercept")
    ),
    warmup = 5000, iter = 20000, chains = 4)

#that "-E" warning is not important--it's a misconfiguration on the developer side (see Stan Forum)
```

#### Plotting our model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_RF)
dimnames(posterior)$variable[1:18]

color_scheme_set("viridis")
```
##### Chain Mixing Plots
```{r}
mcmc_trace(posterior,pars = c("b_Intercept", "b_RNF_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"),
           facet_args = list(ncol = 3))
ggsave("RF_Trace_Plots.png")
```


##### Autocorrelation Plots
```{r}
mcmc_acf(posterior,pars = c("b_Intercept", "b_RNF_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"))
ggsave("RF_Autocor_Plots.png")
```

#### Summaries of the Model
```{r}
summary(fit_RF)
print(summary(fit_RF), digits = 3)
```
Remember, all of these effects are the **medians** of their respective distributions.

Another, perhaps easier to see though less detailed summary
```{r}
describe_posterior(fit_RF)
```



### Competency Model

####Satisfaction
####Fitting our model
```{r}
get_prior(CNS_2_Z ~ CNS_1_Z + Cond + PosAff_Z + pKM_Z,
          data = df)
```

```{r}
fit_CS <- brm(CNS_2_Z ~ CNS_1_Z + Cond + PosAff_Z + pKM_Z,
    data = df,
    prior = c(
      set_prior("normal(0,2)", class = "b", coef = "pKM_Z"),
      set_prior("normal(.10,1)", class = "b", coef = "PosAff_Z"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse"),
      set_prior("normal(0,2)", class = "b", coef = "CondKM"),
      set_prior("normal(0,2)", class = "b", coef = "CNS_1_Z"),
      set_prior("normal(0,2)", class = "Intercept")
    ),
    warmup = 5000, iter = 20000, chains = 4)

#that "-E" warning is not important--it's a misconfiguration on the developer side (see Stan Forum)
```

#### Plotting our model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_CS)
dimnames(posterior)$variable[1:18]

color_scheme_set("viridis")
```
##### Chain Mixing Plots
```{r}
mcmc_trace(posterior,pars = c("b_Intercept", "b_CNS_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"),
           facet_args = list(ncol = 3))
ggsave("CS_Trace_Plots.png")
```


##### Autocorrelation Plots
```{r}
mcmc_acf(posterior,pars = c("b_Intercept", "b_CNS_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"))
ggsave("CS_Autocor_Plots.png")
```

#### Summaries of the Model
```{r}
summary(fit_CS)
print(summary(fit_CS), digits = 3)
```
Remember, all of these effects are the **medians** of their respective distributions.

Another, perhaps easier to see though less detailed summary
```{r}
describe_posterior(fit_CS)
```
We see that PosAffect has appreciable effects on both ANF and ANS in the directions you'd expect (feel good, feel higher ANS and lower ANS).
We also see that KM does have an effect on ANF--where higher KM **increases** Autonomy frustration-- but does nothing to autonomy satisfaction. We might be seeing a reaction to emotional content--a "don't play with my emotions/being-state" that comes from the videso or perhaps just a nature of the KM emotion itself (perhaps culture dependent? UK/Western cultures I think are less culturally accepting of emotionality--though given this is a generally positive emotion, this culture-specificity might not be sufficient)

#### Frustration
```{r}
get_prior(CNF_2_Z ~ CNF_1_Z + Cond + PosAff_Z + pKM_Z,
    data = df)
```

```{r}
fit_CF <- brm(CNF_2_Z ~ CNF_1_Z + Cond + PosAff_Z + pKM_Z,
    data = df,
    prior = c(
      set_prior("normal(0,2)", class = "b", coef = "pKM_Z"),
      set_prior("normal(-.10,1)", class = "b", coef = "PosAff_Z"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse"),
      set_prior("normal(0,2)", class = "b", coef = "CondKM"),
      set_prior("normal(0,2)", class = "b", coef = "CNF_1_Z"),
      set_prior("normal(0,2)", class = "Intercept")
    ),
    warmup = 5000, iter = 20000, chains = 4)

#that "-E" warning is not important--it's a misconfiguration on the developer side (see Stan Forum)
```

#### Plotting our model diagnostics
```{r}
library(bayesplot)
posterior <- as.array(fit_CF)
dimnames(posterior)$variable[1:18]

color_scheme_set("viridis")
```
##### Chain Mixing Plots
```{r}
mcmc_trace(posterior,pars = c("b_Intercept", "b_CNF_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"),
           facet_args = list(ncol = 3))
ggsave("CF_Trace_Plots.png")
```


##### Autocorrelation Plots
```{r}
mcmc_acf(posterior,pars = c("b_Intercept", "b_CNF_1_Z", "b_CondAmuse","b_CondKM", "b_PosAff_Z", "b_pKM_Z", "sigma"))
ggsave("CF_Autocor_Plots.png")
```

#### Summaries of the Model
```{r}
summary(fit_CF)
print(summary(fit_CF), digits = 3)
```
Remember, all of these effects are the **medians** of their respective distributions.

Another, perhaps easier to see though less detailed summary
```{r}
describe_posterior(fit_AF)
```

## Summary of Results

ANS by pKM
```{r}
ggMarginal(
  ggplot(df, aes(x=pKM_Z, y = ANS_2_Z, color = Cond)) +
    geom_point() +
    geom_smooth(method = lm)+
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "T2 ANS Z-Scored"),
  groupColour = T, groupFill = T)
```
ANF
```{r}
ggMarginal(
  ggplot(df, aes(x=pKM_Z, y = ANF_2_Z, color = Cond)) +
    geom_point() +
    geom_smooth(method = lm) +
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "T2 ANF Z-Scored"),
groupColour = T, groupFill = T)
```
RNS
```{r}
ggMarginal(
    ggplot(df, aes(x=pKM_Z, y = RNS_2_Z, color = Cond)) +
      geom_point() +
      geom_smooth(method = lm)+
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "T2 RNS Z-Scored"),
  groupColour = TRUE, groupFill = TRUE)
```
RNF
```{r}
ggMarginal(
    ggplot(df, aes(x=pKM_Z, y = RNF_2_Z, color = Cond)) +
      geom_point() +
      geom_smooth(method = lm)+
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "T2 RNF Z-Scored"),
  groupColour = TRUE, groupFill = TRUE)
```

CNS
```{r}
ggMarginal(
    ggplot(df, aes(x=pKM_Z, y = CNS_2_Z, color = Cond)) +
      geom_point() +
      geom_smooth(method = lm)+
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "T2 CNS Z-Scored"),
  groupColour = TRUE, groupFill = TRUE)
```
CNF
```{r}
ggMarginal(
    ggplot(df, aes(x=pKM_Z, y = CNF_2_Z, color = Cond)) +
      geom_point() +
      geom_smooth(method = lm)+
    scale_colour_discrete(name = "Condition") +
  labs(x = "pKM Z-Scored",
       y = "T2 CNF Z-Scored"),
  groupColour = TRUE, groupFill = TRUE)
```


```{r}
describe_posterior(fit_ARC)
```


## Descriptives, Visualizations, Write-Up Materials
### Exclusions
```{r}
missing_table
```

### Descriptives

```{r}
nrow(df)
```

```{r}
df %>% select(
  Gender, Age, Race, Education, Employed, Income, SexualOr) %>% 
  summary()
```
#### Age
```{r}
sd(df$Age)
```
#### Race
```{r}
table(df$Race)
```

#### Sexual Orientation
```{r}
table(df$SexualOr)
```

#### Student Status
```{r}
table(df$Student)
```
### Visualizations for Write-Up
```{r}
### Visualizing
library(diagram)
names <- c("X", "Y")
M <- matrix(nrow = 2, ncol = 2, byrow = T
            data = c(0, 0,
                     "c", 0),
            dimnames = list(names, 
                           names))

plotmat(M, pos = c(2), relsize = 1.08,
        curve = 0, name = names,
        cex.txt = 1,
        lwd = 1, box.lwd = 2,
        box.type = "square", box.size = 0.07, box.prop = .5)

names <- c("M","X", "Y")
M <- matrix(nrow = 3, ncol = 3, byrow = T,
            data = c(0, "a", 0,
                     0, 0, 0,
                     "b", "c", 0),
            dimnames = list(names, 
                           names))

plotmat(M, pos = c(1,2), relsize = 1.08,
        curve = 0, name = names,
        cex.txt = 1,
        lwd = 1, box.lwd = 2,
        box.type = "square", box.size = 0.07, box.prop = .5)

```

```{r}
library(diagram)
names <- c("pKM", "D1", "Sat", "D2", "Frus", "PA")
M <- matrix(nrow = 6, ncol = 6, byrow = T,
            data = c(0, "A", 0, "B", 0, 0,
                     0,  0,  0,  0,  0, 0,
                     "I","E",0, "F", 0, "K",
                     0,  0,  0,  0,  0,  0,
                     "J","G",0, "H", 0, "L",
                     0, "C", 0, "D", 0, 0),
            dimnames = list(c("pKM", "D1", "Sat", "D2", "Frust", "PA"), 
                            c("pKM", "D1", "Sat", "D2", "Frust", "PA")))

plotmat(M, pos = c(1,2,2,1), relsize = 1.08,
        curve = 0, name = names,
        cex.txt = .8,
        lwd = 1, box.lwd = 2,
        box.type = "square", box.size = 0.07, box.prop = .5)


```
A Basic Sigmoid Function
```{r}
plot(
  x = seq(-3,3,.01),
  y = 1/(1+(exp(1)^-(seq(-3,3,.01)))),
  xlim = c(-3,3),
  xlab = "Range of -3 to +3",
  ylab = "Probability"
)
```


```{r}
get_prior(RNS_2_Z ~ Cond + PosAff_Z + pKM_Z + RNS_1_Z,
    data = df)
```

### Extraneous

To Compare with Sarah's frequentist doublecheck: We'll focus on RNS as our example for simplicity

Trying out as covariate model (not as multilevel) with priors
```{r}
fit_RNS2 <- brm(RNS_2_Z ~ Cond + PosAff_Z + pKM_Z + RNS_1_Z,
    data = df,
    prior = c(
      set_prior("normal(.09,.03)", class = "b", coef = "pKM_Z"),
      set_prior("normal(.10,1)", class = "b", coef = "PosAff_Z"),
      set_prior("normal(0,2)", class = "b", coef = "CondAmuse"),
      set_prior("normal(0,2)", class = "b", coef = "CondKM"),
      set_prior("normal(0,2)", class = "Intercept")
    ),
    warmup = 5000, iter = 10000, chains = 4)
describe_posterior(fit_RNS2)
```

Covariate model without priors, i.e. basically frequentist
```{r}
fit_RNS2 <- brm(RNS_2_Z ~ Cond + PosAff_Z + pKM_Z + RNS_1_Z,
    data = df,
    warmup = 5000, iter = 10000, chains = 4)

describe_posterior(fit_RNS2)
```
Ok, this "frequentist/no prior bayes" is exactly what Sarah's frequentist SPSS output was. Which is good.
Looks like the priors are doing their job--giving narrower CIs and influencing our ultimate estimates based on prev info (priors actually do the thing! Cool to directly see) 